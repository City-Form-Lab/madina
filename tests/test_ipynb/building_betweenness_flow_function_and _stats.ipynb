{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expanding Madina\n",
    "## Goals\n",
    "* Implementing a betweenness flow sumulation function that just can be called from a zonal object with minimal parameters\n",
    "* implementing a dunction that takews count data and outputs a list of statistical models and thwir interporetation\n",
    "* set up a complete docstring template that's compliant and complete..\n",
    "* use code to run sommerville, run stats and interpret\n",
    "* publish the docstring on cityformlab.mit.edu or on github.com\n",
    "* use code to runn Beirut, interpret results\n",
    "* use mofel to run Melbourn, NYC,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from shapely.ops import transform\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from madina.zonal import Layer\n",
    "from madina.zonal import Zonal\n",
    "from madina.una import parallel_betweenness\n",
    "from madina.una import get_elastic_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.24.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.9.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shapely\n",
    "shapely.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pygeos.lib.Geometry"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pygeos\n",
    "pygeos.Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger():\n",
    "    def __init__(self, output_folder):\n",
    "        self.output_folder = output_folder\n",
    "        self.start_time = datetime.now()\n",
    "        self.log_df = pd.DataFrame(\n",
    "            {\n",
    "                \"time\": pd.Series(dtype='datetime64[ns]'),\n",
    "                \"distance\": pd.Series(dtype=\"string\"),\n",
    "                \"tune_penalty\": pd.Series(dtype=\"string\"),\n",
    "                \"elastic_weight\": pd.Series(dtype=\"string\"),\n",
    "                \"origin\": pd.Series(dtype=\"string\"),\n",
    "                \"destination\": pd.Series(dtype=\"string\"),\n",
    "                \"event\": pd.Series(dtype=\"string\")\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def simulation_start(self, zone, network_weight_settings, turn_penalty_settings, elastic_weight_settings):\n",
    "        ##-------------------------------------------------------------------------------------------------------------< Betweenness Recode...\n",
    "        self.betweenness_record = zone.layers['streets'].gdf.copy(deep=True)\n",
    "        self.separate_simulation_records = {}\n",
    "        for network_weight in network_weight_settings:\n",
    "            self.separate_simulation_records[network_weight] = {}\n",
    "            for turn_penalty in turn_penalty_settings:\n",
    "                self.separate_simulation_records[network_weight][turn_penalty] = {}\n",
    "                for elastic_weight in elastic_weight_settings:\n",
    "                    self.separate_simulation_records[network_weight][turn_penalty][elastic_weight] = self.betweenness_record.copy(deep=True)\n",
    "\n",
    "    def log(self, input_dict):\n",
    "        input_dict[\"time\"] = datetime.now()\n",
    "        if self.log_df.shape[0] == 0:\n",
    "            print(f\"total time\\tseconds elapsed\\tdiatance method\\telastic_weight\\t{'origin':^15s}\\t{'destination':^15s}\\tevent\")\n",
    "            input_dict[\"seconds_elapsed\"] = 0\n",
    "            input_dict[\"cumulative_seconds\"] = 0\n",
    "        else:\n",
    "            time_elapsed = (input_dict[\"time\"] - self.log_df.iloc[-1][\"time\"]).seconds\n",
    "            input_dict[\"seconds_elapsed\"] = time_elapsed\n",
    "            input_dict[\"cumulative_seconds\"] = self.log_df[\"seconds_elapsed\"].sum() + time_elapsed\n",
    "\n",
    "        for column_name in self.log_df.columns:\n",
    "            if column_name not in input_dict:\n",
    "                input_dict[column_name] = \"---\"\n",
    "\n",
    "        self.log_df = pd.concat([self.log_df, pd.DataFrame([input_dict])], ignore_index=True)\n",
    "        print(\n",
    "            f\"{input_dict['cumulative_seconds']:6.4f}\\t\\t\"\n",
    "            f\"{input_dict['seconds_elapsed']}\\t\\t\\t\\t\"\n",
    "            f\"{input_dict['distance']}\\t\\t\"\n",
    "            f\"{input_dict['tune_penalty']}\\t\\t\"\n",
    "            f\"{input_dict['elastic_weight']}\\t\\t\"\n",
    "            f\"{input_dict['origin']:^15s}\\t\"\n",
    "            f\"{input_dict['destination']:^15s}\\t\"\n",
    "            f\"{input_dict['event']}\"\n",
    "        )\n",
    "\n",
    "    def pairing_end(self, shaqra: Zonal, pairing, network_weight, turn_penalty, elastic_weight):\n",
    "        # creating a folder for output\n",
    "        pairing_folder = self.output_folder + f\"{network_weight}\\\\{'with_turns' if turn_penalty else 'no_turns'}\\\\{'elastic_weight' if elastic_weight else 'unadjusted_weight'}\\\\O({pairing['Origin_Name']})_D({pairing['Destination_Name']})\\\\\"\n",
    "        Path(pairing_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        street_gdf = shaqra.layers[\"streets\"].gdf\n",
    "        node_gdf = shaqra.network.nodes\n",
    "        origin_gdf = node_gdf[node_gdf[\"type\"] == \"origin\"]\n",
    "        destination_gdf = node_gdf[node_gdf[\"type\"] == \"destination\"]\n",
    "        edge_gdf = shaqra.network.edges\n",
    "        edge_gdf[\"width\"] = edge_gdf[\"betweenness\"] / edge_gdf[\"betweenness\"].mean() + 0.25\n",
    "\n",
    "\n",
    "        self.betweenness_record = self.betweenness_record.join(\n",
    "            edge_gdf[['parent_street_id', 'betweenness']].set_index('parent_street_id')).rename(\n",
    "            columns={\n",
    "                \"betweenness\": f\"{network_weight}_{'with_turns' if turn_penalty else 'no_turns'}_{'elastic_weight' if elastic_weight else 'unadjusted_weight'}_{pairing['Between_Name']}\"})\n",
    "\n",
    "        self.separate_simulation_records[network_weight][turn_penalty][elastic_weight] = \\\n",
    "        self.separate_simulation_records[network_weight][turn_penalty][elastic_weight].join(\n",
    "            edge_gdf[['parent_street_id', 'betweenness']].set_index('parent_street_id')).rename(\n",
    "            columns={\n",
    "                \"betweenness\": f\"{network_weight}_{'with_turns' if turn_penalty else 'no_turns'}_{'elastic_weight' if elastic_weight else 'unadjusted_weight'}_{pairing['Between_Name']}\"})\n",
    "\n",
    "        save_results = \\\n",
    "            edge_gdf.set_index('parent_street_id').join(street_gdf, lsuffix='_from_edge')[\n",
    "                # , rsuffix='_from_streets'\n",
    "                [\"betweenness\", \"__GUID\", \"geometry\"]]\n",
    "        save_results = save_results.rename(\n",
    "            columns={\n",
    "                \"betweenness\": f\"{network_weight}_{'with_turns' if turn_penalty else 'no_turns'}_{'elastic_weight' if elastic_weight else 'unadjusted_weight'}_{pairing['Between_Name']}\"})\n",
    "\n",
    "        save_results.to_csv(pairing_folder + \"flows.csv\")\n",
    "        # save_results.to_file(pairing_folder + \"flows.geojson\", driver=\"GeoJSON\")\n",
    "        self.betweenness_record.to_csv(pairing_folder + \"betweenness_record_so_far.csv\")\n",
    "        self.separate_simulation_records[network_weight][turn_penalty][elastic_weight].to_csv(\n",
    "            pairing_folder + \"simulation_record_so_far.csv\")\n",
    "\n",
    "        self.log_df.to_csv(pairing_folder + \"time_log.csv\")\n",
    "\n",
    "        self.log({\n",
    "            \"origin\": pairing[\"Origin_Name\"],\n",
    "            \"destination\": pairing[\"Destination_Name\"],\n",
    "            \"event\": \"Output saved\",\n",
    "            \"distance\": network_weight,\n",
    "            \"tune_penalty\": turn_penalty,\n",
    "            \"elastic_weight\": elastic_weight})\n",
    "\n",
    "    def simulation_end(self, network_weight_settings, turn_penalty_settings, elastic_weight_settings):\n",
    "        self.betweenness_record.to_csv(self.output_folder + \"betweenness_record.csv\")\n",
    "        #self.betweenness_record.to_file(self.output_folder + \"street_network_betweenness_record.geojson\", driver=\"GeoJSON\")\n",
    "        for network_weight in network_weight_settings:\n",
    "            for turn_penalty in turn_penalty_settings:\n",
    "                for elastic_weight in elastic_weight_settings:\n",
    "                    pairing_folder = self.output_folder + f\"{network_weight}\\\\{'with_turns' if turn_penalty else 'no_turns'}\\\\{'elastic_weight' if elastic_weight else 'unadjusted_weight'}\\\\\"\n",
    "                    self.separate_simulation_records[network_weight][turn_penalty][elastic_weight].to_csv(pairing_folder+\"betweenness_record.csv\")\n",
    "        self.log({\"event\": \"All DONE.\"})\n",
    "        self.log_df.to_csv(self.output_folder + \"time_log.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def betweenness_flow_simulation(\n",
    "        city_name=\"Somerville\",\n",
    "        data_folder=None,\n",
    "        output_folder=None,\n",
    "        pairings_file=\"Pairings.csv\",\n",
    "        network_weight_settings = [\"Perceived\", \"Geometric\"],\n",
    "        turn_penalty_settings = [False, True],\n",
    "        elastic_weight_settings = [False, True],\n",
    "        num_cores=8,\n",
    "        turn_threshold_degree=45,\n",
    "        turn_penalty_amount=30,\n",
    "        impose_crs=None\n",
    "    ):\n",
    "    '''\n",
    "    WHat used to be a major project, is now implemented into this standard workflow.....\n",
    "    '''\n",
    "    # Validate user input parameters, raise exceptions or make modifications..\n",
    "    if data_folder is None:\n",
    "        data_folder = \"Cities\\\\\"+city_name+\"\\\\Data\\\\\"\n",
    "    if output_folder is None:\n",
    "        start_time = datetime.now()\n",
    "        output_folder = f\"Cities\\\\{city_name}\\\\Simulations\\\\{start_time.year}_{start_time.month:02d}_{start_time.day:02d}_{start_time.hour:02d}_{start_time.minute:02d}\\\\\"\n",
    "\n",
    "    logger=Logger(output_folder)\n",
    "    logger.log({\"event\": \"beginning\"})\n",
    "\n",
    "    pairings = gpd.read_file(data_folder + pairings_file)\n",
    "\n",
    "    zonal = Zonal()\n",
    "    if impose_crs is not None:\n",
    "        zonal = Zonal(projected_crs=impose_crs)\n",
    "\n",
    "    zonal.load_layer(\n",
    "        layer_name='streets',\n",
    "        file_path=data_folder +  pairings.at[0, \"Network_File\"]  # \"Network.geojson\"\n",
    "    )\n",
    "    if impose_crs is not None:\n",
    "        zonal.layers[\"streets\"] = Layer(\n",
    "            label=\"streets\",\n",
    "            gdf=gpd.read_file(data_folder +  pairings.at[0, \"Network_File\"]).set_crs(impose_crs, allow_override=True),\n",
    "            show=True,\n",
    "            original_crs=impose_crs,\n",
    "            file_path=(data_folder + pairings.at[0, \"Network_File\"])\n",
    "        )\n",
    "\n",
    "    ##-------------------------------------------------------------------------------------------------------------< Data Cleaning/...\n",
    "    geometry_gdf = zonal.layers[\"streets\"].gdf\n",
    "    polygon_idxs = geometry_gdf[geometry_gdf[\"geometry\"].geom_type == \"Polygon\"].index\n",
    "    geometry_gdf.loc[polygon_idxs,\"geometry\"] = geometry_gdf.loc[polygon_idxs, \"geometry\"].exterior\n",
    "    zonal.layers[\"streets\"].gdf = geometry_gdf\n",
    "\n",
    "    if zonal.layers[\"streets\"].gdf.has_z.any():\n",
    "        def _to_2d(x, y, z):\n",
    "            return tuple(filter(None, [x, y]))\n",
    "        zonal.layers[\"streets\"].gdf[\"geometry\"] = zonal.layers[\"streets\"].gdf[\n",
    "            \"geometry\"].apply(lambda s: transform(_to_2d, s))\n",
    "\n",
    "    if (zonal.layers[\"streets\"].gdf.geometry.geom_type == \"MultiLineString\").all():\n",
    "        zonal.layers[\"streets\"].gdf[\"geometry\"] = zonal.layers[\"streets\"].gdf[\n",
    "            \"geometry\"].apply(lambda s: s.geoms[0])\n",
    "\n",
    "    print(f'streets\\t{zonal.layers[\"streets\"].gdf.crs}')\n",
    "\n",
    "    logger.simulation_start(zonal, network_weight_settings, turn_penalty_settings, elastic_weight_settings)\n",
    "\n",
    "    # Setting up a street network\n",
    "    zonal.create_street_network(\n",
    "        source_layer=\"streets\",\n",
    "        node_snapping_tolerance=1,\n",
    "        weight_attribute=None if \"Perceived\" not in network_weight_settings else pairings.at[0, \"Network_Cost\"],\n",
    "        discard_redundant_edges=True, # <---------------------------------------TODO: Expose as a parameter\n",
    "        turn_threshold_degree=turn_threshold_degree,\n",
    "        turn_penalty_amount=turn_penalty_amount\n",
    "        )\n",
    "    # This is to re-set the origins and destinations before any new iteration. TODO: implement as a Zonal function.\n",
    "    clean_node_gdf = zonal.network.nodes.copy(deep=True)\n",
    "\n",
    "    # preparing percieved and geometric weights...\n",
    "    perceived_network_weight = zonal.network.edges[\"weight\"]\n",
    "    perceived_network_weight = perceived_network_weight.apply(lambda x: max(1, x))      # To avoid any negative numbers...\n",
    "    geometric_network_weight = zonal.network.edges[\"geometry\"].length\n",
    "\n",
    "    logger.log({\"event\": \"Network topology created.\"})\n",
    "\n",
    "    for idx, pairing in pairings.iterrows():\n",
    "        # Loading layers,  if they're not already loaded.\n",
    "        if pairing[\"Origin_Name\"] not in zonal.layers:\n",
    "            zonal.load_layer(\n",
    "                layer_name=pairing[\"Origin_Name\"],\n",
    "                file_path=data_folder + pairing[\"Origin_File\"]\n",
    "            )\n",
    "            print(f\"{pairing['Origin_Name']}\\t{zonal.layers[pairing['Origin_Name']].gdf.crs}\")\n",
    "            if (impose_crs is not None) and (zonal.layers[pairing[\"Origin_Name\"]].gdf.crs != impose_crs):\n",
    "                print(\"Imposing CRS\", impose_crs)\n",
    "                # zonal.layers[pairing[\"Origin_Name\"]].gdf = gpd.read_file(data_folder + pairing[\"Origin_File\"]).set_crs(impose_crs, allow_override=True)\n",
    "                # zonal.layers[pairing[\"Origin_Name\"]].crs = impose_crs\n",
    "                zonal.layers[pairing[\"Origin_Name\"]] = Layer(\n",
    "                    label=pairing[\"Origin_Name\"],\n",
    "                    gdf=gpd.read_file(data_folder + pairing[\"Origin_File\"]).set_crs(impose_crs, allow_override=True),\n",
    "                    show=True,\n",
    "                    original_crs=impose_crs,\n",
    "                    file_path=(data_folder + pairing[\"Origin_File\"])\n",
    "                )\n",
    "\n",
    "            print(f\"{pairing['Origin_Name']}\\t{zonal.layers[pairing['Origin_Name']].gdf.crs}\\t{zonal.layers[pairing['Origin_Name']].crs}\")\n",
    "\n",
    "\n",
    "            ##-------------------------------------------------------------------------------------------------------------< Data Cleaning/...\n",
    "            if zonal.layers[pairing[\"Origin_Name\"]].gdf.has_z.any():\n",
    "                # zonal.layers[pairing[\"Origin_Name\"]].gdf[\"geometry\"] = zonal.layers[pairing[\"Origin_Name\"]].gdf[\"geometry\"].apply(\n",
    "                #     lambda s: transform(_to_2d, s))\n",
    "                zonal.layers[pairing[\"Origin_Name\"]] = Layer(\n",
    "                    label=pairing[\"Origin_Name\"],\n",
    "                    gdf=zonal.layers[pairing[\"Origin_File\"]].gdf[\"geometry\"].apply(lambda s: transform(_to_2d, s)),\n",
    "                    show=True,\n",
    "                    original_crs=impose_crs,\n",
    "                    file_path=(data_folder + pairing[\"Origin_File\"])\n",
    "                )\n",
    "\n",
    "        if pairing[\"Destination_Name\"] not in zonal.layers:\n",
    "            zonal.load_layer(\n",
    "                layer_name=pairing[\"Destination_Name\"],\n",
    "                file_path=data_folder + pairing[\"Destination_File\"]\n",
    "            )\n",
    "            if (impose_crs is not None) and (zonal.layers[pairing[\"Destination_Name\"]].gdf.crs != impose_crs):\n",
    "                # zonal.layers[pairing[\"Destination_Name\"]].gdf = gpd.read_file(data_folder + pairing[\"Destination_File\"]).set_crs(impose_crs, allow_override=True)\n",
    "                # zonal.layers[pairing[\"Destination_Name\"]].crs = impose_crs\n",
    "                zonal.layers[pairing[\"Destination_Name\"]] = Layer(\n",
    "                    label=pairing[\"Destination_Name\"],\n",
    "                    gdf=gpd.read_file(data_folder + pairing[\"Destination_File\"]).set_crs(impose_crs, allow_override=True),\n",
    "                    show=True,\n",
    "                    original_crs=impose_crs,\n",
    "                    file_path=(data_folder + pairing[\"Destination_File\"])\n",
    "                )\n",
    "            ##-------------------------------------------------------------------------------------------------------------< Data Cleaning/...\n",
    "            if zonal.layers[pairing[\"Destination_Name\"]].gdf.has_z.any():\n",
    "                # zonal.layers[pairing[\"Destination_Name\"]].gdf[\"geometry\"] = zonal.layers[pairing[\"Destination_Name\"]].gdf[\n",
    "                #     \"geometry\"].apply(lambda s: transform(_to_2d, s))\n",
    "                zonal.layers[pairing[\"Destination_Name\"]] = Layer(\n",
    "                    label=pairing[\"Destination_Name\"],\n",
    "                    gdf=zonal.layers[pairing[\"Destination_File\"]].gdf[\"geometry\"].apply(lambda s: transform(_to_2d, s)),\n",
    "                    show=True,\n",
    "                    original_crs=impose_crs,\n",
    "                    file_path=(data_folder + pairing[\"Destination_File\"])\n",
    "                )\n",
    "        \n",
    "        print(f\"{pairing['Origin_Name']}\\t{zonal.layers[pairing['Origin_Name']].gdf.crs}\")\n",
    "        print(f\"{pairing['Destination_Name']}\\t{zonal.layers[pairing['Destination_Name']].gdf.crs}\")\n",
    "\n",
    "        # making sure to clear any existing origins and destinations before adding new ones.\n",
    "        zonal.network.nodes = clean_node_gdf.copy(deep=True)\n",
    "\n",
    "        # iterating over network weight options..\n",
    "        for network_weight in network_weight_settings:\n",
    "\n",
    "            # setting the proper network_weight\n",
    "            if network_weight == \"Perceived\":\n",
    "                zonal.network.nodes[\"weight\"] = perceived_network_weight\n",
    "            elif network_weight == \"Geometric\":\n",
    "                zonal.network.edges[\"weight\"] = geometric_network_weight\n",
    "\n",
    "            # using an effecient insert algorithm TODO: should be built inti the main Madina code... currently imported from betweenness function..\n",
    "            zonal.insert_node(\n",
    "                label=\"origin\",\n",
    "                layer_name=pairing[\"Origin_Name\"],\n",
    "                weight_attribute=pairing[\"Origin_Weight\"] if pairing[\"Origin_Weight\"] != \"Count\" else None,\n",
    "            )\n",
    "\n",
    "            zonal.insert_node(\n",
    "                label=\"destination\",\n",
    "                layer_name=pairing[\"Destination_Name\"],\n",
    "                weight_attribute=pairing[\"Destination_Weight\"] if pairing[\"Destination_Weight\"] != \"Count\" else None,\n",
    "            )\n",
    "\n",
    "            inelastic_weight = zonal.network.nodes['weight']\n",
    "\n",
    "\n",
    "            logger.log({\n",
    "                \"origin\": pairing[\"Origin_Name\"],\n",
    "                \"destination\": pairing[\"Destination_Name\"],\n",
    "                \"event\": \"Origins and Destinations prepared.\"\n",
    "                })\n",
    "\n",
    "            zonal.create_graph(light_graph=True, od_graph=True)\n",
    "\n",
    "            logger.log({\n",
    "                \"origin\": pairing[\"Origin_Name\"],\n",
    "                \"destination\": pairing[\"Destination_Name\"],\n",
    "                \"event\": \"Light and dense graphs prepared.\"\n",
    "                })\n",
    "\n",
    "            for turn_penalty in turn_penalty_settings:\n",
    "                # TODO: Investigate the value of pasing internal calculations beween simulations..\n",
    "                #retained_d_idxs = {}\n",
    "                #retained_paths = {}\n",
    "                #retained_distances = {}\n",
    "                for elastic_weight in elastic_weight_settings:\n",
    "                    # The order of these is important, as the weight is overriden by\n",
    "                    # elastic weight as there is no clean way to update weight for now.\n",
    "                    if elastic_weight:\n",
    "                        get_elastic_weight(\n",
    "                            zonal.network,\n",
    "                            search_radius=800,\n",
    "                            detour_ratio=0.002,\n",
    "                            beta=0.002,\n",
    "                            decay=True,\n",
    "                            turn_penalty=turn_penalty,\n",
    "                            retained_d_idxs=None  #<------------------- This is very sensitive to the orfer of iteration. TODO: change to a more solid implementation\n",
    "                            #retained_d_idxs=None\n",
    "                            )\n",
    "\n",
    "                        logger.log({\n",
    "                            \"origin\": pairing[\"Origin_Name\"],\n",
    "                            \"destination\": pairing[\"Destination_Name\"],\n",
    "                            \"event\": \"Elastic Weights generated.\",\n",
    "                            \"distance\": network_weight, \"tune_penalty\": turn_penalty,\n",
    "                            \"elastic_weight\": elastic_weight})\n",
    "                    else:\n",
    "                        zonal.network.nodes['weight'] = inelastic_weight\n",
    "\n",
    "\n",
    "                    node_gdf = zonal.network.nodes\n",
    "                    origin_gdf = node_gdf[node_gdf[\"type\"] == \"origin\"]\n",
    "\n",
    "                    num_cores = min(origin_gdf.shape[0], num_cores) # if not elastic_weight else 1\n",
    "\n",
    "                    betweenness_output = parallel_betweenness(\n",
    "                        zonal.network,\n",
    "                        search_radius=float(pairing[\"Radius\"]),\n",
    "                        detour_ratio=float(pairing[\"Detour\"]),\n",
    "                        decay=False if elastic_weight else True,\n",
    "                        decay_method=\"exponent\",  # \"power\", \"exponent\"\n",
    "                        beta=float(pairing[\"Beta\"]),\n",
    "                        path_detour_penalty=\"equal\",  # \"power\", \"exponent\", \"equal\"\n",
    "                        origin_weights=True,\n",
    "                        closest_destination=False,\n",
    "                        destination_weights=True,  # if pairing[\"Destination_Name\"] != \"Mosques\" else False,\n",
    "                        # perceived_distance=False,\n",
    "                        num_cores=num_cores,\n",
    "                        light_graph=True,\n",
    "                        turn_penalty=turn_penalty,\n",
    "                        #retained_d_idxs=retained_d_idxs if elastic_weight else None,\n",
    "                        #retained_paths=retained_paths if elastic_weight else None,\n",
    "                        #retained_distances=retained_distances if elastic_weight else None,\n",
    "                        rertain_expensive_data=False if elastic_weight else True,\n",
    "                        retained_d_idxs=None,\n",
    "                        retained_paths=None,\n",
    "                        retained_distances=None,\n",
    "                        #rertain_expensive_data=False\n",
    "                    )\n",
    "\n",
    "                    if not elastic_weight: #< -------------------------------------------------------- sensitive to order of looping #TODO: implement for more general case.\n",
    "                        retained_d_idxs = betweenness_output[\"retained_d_idxs\"]\n",
    "                        #retained_paths = betweenness_output[\"retained_paths\"]\n",
    "                        #retained_distances = betweenness_output[\"retained_distances\"]\n",
    "\n",
    "                    logger.log({\n",
    "                        \"origin\": pairing[\"Origin_Name\"],\n",
    "                        \"destination\": pairing[\"Destination_Name\"],\n",
    "                        \"event\": \"Betweenness estimated.\",\n",
    "                        \"distance\": network_weight,\n",
    "                        \"tune_penalty\": turn_penalty,\n",
    "                        \"elastic_weight\": elastic_weight})\n",
    "                    logger.pairing_end(zonal, pairing, network_weight, turn_penalty, elastic_weight)\n",
    "                    \n",
    "    logger.simulation_end(network_weight_settings, turn_penalty_settings, elastic_weight_settings)\n",
    "    Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "    zonal.network.edges.to_csv(output_folder + \"edge_gdf.csv\")\n",
    "    zonal.network.nodes.to_csv(output_folder + \"node_gdf.csv\")\n",
    "\n",
    "    # zonal.network.nodes.drop(columns=['nearest_street_node_distance']).to_csv(output_folder + \"node_gdf_part_1.csv\")\n",
    "    # zonal.network.nodes['nearest_street_node_distance'].to_csv(output_folder + \"node_gdf_part_2_dict.csv\")\n",
    "    # nearest_street_node = pd.DataFrame({\n",
    "    #     'left_id': [dict(dict(d).get('left')).get('node_id') for d in zonal.network.nodes['nearest_street_node_distance'] if d is not nan],\n",
    "    #     'left_weight': [dict(dict(d).get('left')).get('weight') for d in zonal.network.nodes['nearest_street_node_distance']],\n",
    "    #     'right_id': [dict(dict(d).get('right')).get('node_id') for d in zonal.network.nodes['nearest_street_node_distance']],\n",
    "    #     'right_weight': [dict(dict(d).get('right')).get('weight') for d in zonal.network.nodes['nearest_street_node_distance']]\n",
    "    # })\n",
    "    # nearest_street_node.to_csv(output_folder + \"node_gdf_part_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time\tseconds elapsed\tdiatance method\telastic_weight\t    origin     \t  destination  \tevent\n",
      "0.0000\t\t0\t\t\t\t---\t\t---\t\t---\t\t      ---      \t      ---      \tbeginning\n",
      "\n",
      "Position 1 ----- streets\n",
      "streets\tepsg:26986\n",
      "counter = 100, progress =  0.98\n",
      "counter = 200, progress =  1.96\n",
      "counter = 300, progress =  2.94\n",
      "counter = 400, progress =  3.91\n",
      "counter = 500, progress =  4.89\n",
      "counter = 600, progress =  5.87\n",
      "counter = 700, progress =  6.85\n",
      "counter = 800, progress =  7.83\n",
      "counter = 900, progress =  8.81\n",
      "counter = 1000, progress =  9.78\n",
      "counter = 1100, progress = 10.76\n",
      "counter = 1200, progress = 11.74\n",
      "counter = 1300, progress = 12.72\n",
      "counter = 1400, progress = 13.70\n",
      "counter = 1500, progress = 14.68\n",
      "counter = 1600, progress = 15.65\n",
      "counter = 1700, progress = 16.63\n",
      "counter = 1800, progress = 17.61\n",
      "counter = 1900, progress = 18.59\n",
      "counter = 2000, progress = 19.57\n",
      "counter = 2100, progress = 20.55\n",
      "counter = 2200, progress = 21.52\n",
      "counter = 2300, progress = 22.50\n",
      "counter = 2400, progress = 23.48\n",
      "counter = 2500, progress = 24.46\n",
      "counter = 2600, progress = 25.44\n",
      "counter = 2700, progress = 26.42\n",
      "counter = 2800, progress = 27.39\n",
      "counter = 2900, progress = 28.37\n",
      "counter = 3000, progress = 29.35\n",
      "counter = 3100, progress = 30.33\n",
      "counter = 3200, progress = 31.31\n",
      "counter = 3300, progress = 32.29\n",
      "counter = 3400, progress = 33.26\n",
      "counter = 3500, progress = 34.24\n",
      "counter = 3600, progress = 35.22\n",
      "counter = 3700, progress = 36.20\n",
      "counter = 3800, progress = 37.18\n",
      "counter = 3900, progress = 38.16\n",
      "counter = 4000, progress = 39.14\n",
      "counter = 4100, progress = 40.11\n",
      "counter = 4200, progress = 41.09\n",
      "counter = 4300, progress = 42.07\n",
      "counter = 4400, progress = 43.05\n",
      "counter = 4500, progress = 44.03\n",
      "counter = 4600, progress = 45.01\n",
      "counter = 4700, progress = 45.98\n",
      "counter = 4800, progress = 46.96\n",
      "counter = 4900, progress = 47.94\n",
      "counter = 5000, progress = 48.92\n",
      "counter = 5100, progress = 49.90\n",
      "counter = 5200, progress = 50.88\n",
      "counter = 5300, progress = 51.85\n",
      "counter = 5400, progress = 52.83\n",
      "counter = 5500, progress = 53.81\n",
      "counter = 5600, progress = 54.79\n",
      "counter = 5700, progress = 55.77\n",
      "counter = 5800, progress = 56.75\n",
      "counter = 5900, progress = 57.72\n",
      "counter = 6000, progress = 58.70\n",
      "counter = 6100, progress = 59.68\n",
      "counter = 6200, progress = 60.66\n",
      "counter = 6300, progress = 61.64\n",
      "counter = 6400, progress = 62.62\n",
      "counter = 6500, progress = 63.59\n",
      "counter = 6600, progress = 64.57\n",
      "counter = 6700, progress = 65.55\n",
      "counter = 6800, progress = 66.53\n",
      "counter = 6900, progress = 67.51\n",
      "counter = 7000, progress = 68.49\n",
      "counter = 7100, progress = 69.46\n",
      "counter = 7200, progress = 70.44\n",
      "counter = 7300, progress = 71.42\n",
      "counter = 7400, progress = 72.40\n",
      "counter = 7500, progress = 73.38\n",
      "counter = 7600, progress = 74.36\n",
      "counter = 7700, progress = 75.34\n",
      "counter = 7800, progress = 76.31\n",
      "counter = 7900, progress = 77.29\n",
      "counter = 8000, progress = 78.27\n",
      "counter = 8100, progress = 79.25\n",
      "counter = 8200, progress = 80.23\n",
      "counter = 8300, progress = 81.21\n",
      "counter = 8400, progress = 82.18\n",
      "counter = 8500, progress = 83.16\n",
      "counter = 8600, progress = 84.14\n",
      "counter = 8700, progress = 85.12\n",
      "counter = 8800, progress = 86.10\n",
      "counter = 8900, progress = 87.08\n",
      "counter = 9000, progress = 88.05\n",
      "counter = 9100, progress = 89.03\n",
      "counter = 9200, progress = 90.01\n",
      "counter = 9300, progress = 90.99\n",
      "counter = 9400, progress = 91.97\n",
      "counter = 9500, progress = 92.95\n",
      "counter = 9600, progress = 93.92\n",
      "counter = 9700, progress = 94.90\n",
      "counter = 9800, progress = 95.88\n",
      "counter = 9900, progress = 96.86\n",
      "counter = 10000, progress = 97.84\n",
      "counter = 10100, progress = 98.82\n",
      "counter = 10200, progress = 99.79\n",
      "redundant edge report: zero_length_edges = 15, redundant_edges = 80\n",
      "191.0000\t\t191\t\t\t\t---\t\t---\t\t---\t\t      ---      \t      ---      \tNetwork topology created.\n",
      "\n",
      "Position 2 ----- Bus\n",
      "Position 1 ----- streets\n",
      "Bus\tepsg:26986\n",
      "Bus\tepsg:26986\tepsg:26986\n",
      "\n",
      "Position 3 ----- Subway\n",
      "Position 2 ----- Bus\n",
      "Position 1 ----- streets\n",
      "Bus\tepsg:26986\n",
      "Subway\tepsg:26986\n",
      "checking insert_node\n",
      "streets\n",
      "Bus\n",
      "Subway\n",
      "Bus RangeIndex(start=0, stop=573, step=1)\n",
      "checking insert_node\n",
      "streets\n",
      "Bus\n",
      "Subway\n",
      "Subway RangeIndex(start=0, stop=11, step=1)\n",
      "191.0000\t\t0\t\t\t\t---\t\t---\t\t---\t\t      Bus      \t    Subway     \tOrigins and Destinations prepared.\n",
      "191.0000\t\t0\t\t\t\t---\t\t---\t\t---\t\t      Bus      \t    Subway     \tLight and dense graphs prepared.\n",
      "212.0000\t\t21\t\t\t\tGeometric\t\tTrue\t\tTrue\t\t      Bus      \t    Subway     \tElastic Weights generated.\n",
      "-------------------------------------------\n",
      "All cores done in 6.26\n",
      "-------------------------------------------\n",
      "218.0000\t\t6\t\t\t\tGeometric\t\tTrue\t\tTrue\t\t      Bus      \t    Subway     \tBetweenness estimated.\n",
      "220.0000\t\t2\t\t\t\tGeometric\t\tTrue\t\tTrue\t\t      Bus      \t    Subway     \tOutput saved\n",
      "\n",
      "Position 4 ----- Home\n",
      "Position 3 ----- Subway\n",
      "Position 2 ----- Bus\n",
      "Position 1 ----- streets\n",
      "Home\tepsg:26986\n",
      "Home\tepsg:26986\tepsg:26986\n",
      "Home\tepsg:26986\n",
      "Subway\tepsg:26986\n",
      "checking insert_node\n",
      "streets\n",
      "Bus\n",
      "Subway\n",
      "Home\n",
      "Home RangeIndex(start=0, stop=35344, step=1)\n",
      "checking insert_node\n",
      "streets\n",
      "Bus\n",
      "Subway\n",
      "Home\n",
      "Subway RangeIndex(start=0, stop=11, step=1)\n",
      "236.0000\t\t16\t\t\t\t---\t\t---\t\t---\t\t     Home      \t    Subway     \tOrigins and Destinations prepared.\n",
      "247.0000\t\t11\t\t\t\t---\t\t---\t\t---\t\t     Home      \t    Subway     \tLight and dense graphs prepared.\n",
      "1438.0000\t\t1191\t\t\t\tGeometric\t\tTrue\t\tTrue\t\t     Home      \t    Subway     \tElastic Weights generated.\n",
      "-------------------------------------------\n",
      "All cores done in 384.93\n",
      "-------------------------------------------\n",
      "1823.0000\t\t385\t\t\t\tGeometric\t\tTrue\t\tTrue\t\t     Home      \t    Subway     \tBetweenness estimated.\n",
      "1824.0000\t\t1\t\t\t\tGeometric\t\tTrue\t\tTrue\t\t     Home      \t    Subway     \tOutput saved\n",
      "1825.0000\t\t1\t\t\t\t---\t\t---\t\t---\t\t      ---      \t      ---      \tAll DONE.\n"
     ]
    }
   ],
   "source": [
    "betweenness_flow_simulation(\n",
    "    city_name=\"Somerville\",\n",
    "    data_folder=f'Cities\\\\Somerville\\\\Data\\\\',\n",
    "    pairings_file=\"Pairings.csv\",\n",
    "    network_weight_settings=[\"Geometric\"],          # [\"Perceived\", \"Geometric\"],\n",
    "    turn_penalty_settings=[True],                   # [False, True]\n",
    "    elastic_weight_settings=[True],          # [False, True]\n",
    "    num_cores=20,\n",
    "    turn_threshold_degree=45,\n",
    "    turn_penalty_amount=62.3,\n",
    "    impose_crs='epsg:26986'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
