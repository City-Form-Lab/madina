{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potential Speedup imporvements\n",
    "\n",
    "path generation\n",
    "* remove any use of ROUND()\n",
    "* while returning paths, make sure all nodes in the paths are network nodes (no origin or destination nodes..).\n",
    "\n",
    "subgraph generation\n",
    "* consoliate + weight\n",
    "\n",
    "destination discovery\n",
    "* stop searching for origin nodes past 0.5 search radius\n",
    "* remove duplicate if statements\n",
    "\n",
    "\n",
    "update light graph\n",
    "* shorter list of segments to iterate over\n",
    "* one add one remove\n",
    "\n",
    "\n",
    "betweenness\n",
    "* remove decay calculations from inner loop.\n",
    "* vectorize betweenness calculation outside path loop\n",
    "* reduce calls to node_gdf.at[] by doing them when thwey're first possible, instead of inside path loop\n",
    "* vectorize destination probability calculations\n",
    "\n",
    "\n",
    "\n",
    "path generation\n",
    "* return paths as edges\n",
    "* remove len(neighbors) = 1 check, causes excessive calls to neighbors.\n",
    "* consolidate edge information retreval from graph.\n",
    "\n",
    "betweenness\n",
    "* eliminate edge list construction inside loop.\n",
    "\n",
    "parallel Betweenness:\n",
    "* Implement a queue for parallel processing\n",
    "* better reporting from quue progress\n",
    "\n",
    "Betweenness\n",
    "* update to accomidate queue feeding\n",
    "* implement controls for starting a job only when there is enough memory...\n",
    "* selete large variable prior to next job, so save for memory when waiting for memory to free up\n",
    "\n",
    "path generation:\n",
    "* remove edge sets, sacrificing time performance for memory savings\n",
    "* slightly more optimized scope neighbor, use set operations to filter neighbors in scope, instead of list comprehension with checking..\n",
    "* experament with dequeue for cheaper path appends...\n",
    "* significiant memory redunction by eliminating need to store \"targets remaining\", this might lead to reduction in cpu effeciency?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For next week:\n",
    "* Send rounaq wide table of counts\n",
    "* Once recieved, from lui, start a new digitization process in the new network\n",
    "* look at th eparks file situation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionality List 3\n",
    "* set up a slideshow/diagram to show the relationship between different compoonents of the library.\n",
    "* Set up a notebook to go over estimating flows from one origin to one destination, Document all relevant settings\n",
    "* show how this generalizes to the pairings.csv, iterating over moodel settings, iterating over scenarios\n",
    "* Make a finalized github commit including testing script, betweenness flow notebook. \n",
    "* Deploy to workstation.\n",
    "* given the simulation results, and the censor locations, find a way to calibrate counts and generate beta coeffecients (Beirut, SOmerville, NYC)\n",
    "* enable Jupyter notebook server access from workstation.\n",
    "* Figure out a way to do the \"Cities\" dropbox folder, people can add data through dropbox, run simulations through Jupyter Server, get results through Dropbox\n",
    "\n",
    "## Map Cleaning\n",
    "https://www.dropbox.com/scl/fo/d6ugcyt3aanfb3yk4n9va/h?dl=0&rlkey=1c2giilvzoyygcxrlry7fscr9\n",
    "\n",
    "\n",
    "\n",
    "## Needed compatibility upgrades:\n",
    "* The query_bulk() method of the spatial index .sindex property is deprecated in favor of query() (#2823).\n",
    "* Make surr there is no direct use of pyGEOS (currently used in node-edge creation if tolerance=0) [ If you use PyGEOS directly and access an array of PyGEOS geometries using GeoSeries.values.data, you will need to make some changes to avoid code breakage.]  , a simple replacement of pygeos with shapely together with a change of gdf.geometry.values.data to gdf.geometry.values or analogous gdf.geometry.array should work\n",
    "\n",
    "\n",
    "## instaling an environment\n",
    "```\n",
    "Run Powershell as administrator\n",
    "\n",
    "conda create --name=madina_0_0_2 python\n",
    "conda activate madina_0_0_2\n",
    "conda config --env --add channels conda-forge\n",
    "conda config --env --set channel_priority strict\n",
    "conda install -f mkl\n",
    "conda install python=3 geopandas\n",
    "conda install pydeck\n",
    "conda install pyogrio\n",
    "conda install rtrees\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test name                      | madina_flow_sum | Rhino_flow_sum  | sum_diff | sum_smlr_% | sle_mean | sle_median | sle_max  | sle>0.1% | sle>1.0% | sle>3.0% | sle>5.0% | time_spent\n",
      "_Betweenness1                  |          702.07 |          702.07 |    -0.00 |    100.00% |  0.0000% |    0.0000% |  0.0000% |        0 |        0 |        0 |        0 |    5.54719\n",
      "_Betweenness2                  |        19025.63 |        19025.63 |     0.00 |    100.00% |  0.0000% |    0.0000% |  0.0000% |        0 |        0 |        0 |        0 |    9.78929\n",
      "_Betweenness3                  |        19214.00 |        19214.00 |     0.00 |    100.00% |  0.0000% |    0.0000% |  0.0000% |        0 |        0 |        0 |        0 |   13.53642\n",
      "_Betweenness4                  |        20853.18 |        20853.18 |    -0.00 |    100.00% |  0.0000% |    0.0000% |  0.0000% |        0 |        0 |        0 |        0 |   17.22583\n",
      "Somerville_Bus_Subway_Geometri |          713.14 |          713.14 |    -0.00 |    100.00% |  0.0000% |    0.0000% |  0.0000% |        0 |        0 |        0 |        0 |   14.98791\n",
      "Somerville_Bus_Subway          |          743.95 |          743.95 |    -0.00 |    100.00% |  0.0000% |    0.0000% |  0.0000% |        0 |        0 |        0 |        0 |   30.86326\n",
      "Somerville_Homes_Subway        |       390916.79 |       389383.31 |  1533.48 |     99.61% |     inf% |    0.3608% |     inf% |     1548 |     1087 |      687 |      491 |  269.85510\n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "from madina.zonal.zonal import Zonal\n",
    "from madina.una.betweenness import parallel_betweenness, paralell_betweenness_exposure, betweenness_exposure\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import time \n",
    "\n",
    "\n",
    "\n",
    "print (f\"{'test name':30s} | {'madina_flow_sum':15s} | {'Rhino_flow_sum':15s} | {'sum_diff':8s} | {'sum_smlr_%':10s} | {'sle_mean':8s} | {'sle_median':10s} | {'sle_max':8s} | {'sle>0.1%':8s} | {'sle>1.0%':8s} | {'sle>3.0%':8s} | {'sle>5.0%':8s} | {'time_spent':10s}\")\n",
    "#for test_case in os.listdir(\"Test Cases\"):\n",
    "for test_case in ['Harvard Square', 'Somerville']:   # 'Harvard Square',\n",
    "    start = time.time()\n",
    "    # TODO: Check OS compatibility, ensure this is compatible with Unix systems..\n",
    "    test_case_folder = \"Test Cases\" + \"\\\\\" + test_case + \"\\\\\"\n",
    "    test_config = pd.read_csv(test_case_folder + \"test_configs.csv\")\n",
    "    test_flows =  pd.read_csv(test_case_folder + \"test_flows.csv\")\n",
    "\n",
    "    if test_case == 'Somerville':\n",
    "        ready_tests = test_config.index[0:3]\n",
    "    else:\n",
    "        ready_tests = test_config.index\n",
    "\n",
    "    for test_idx in ready_tests:\n",
    "\n",
    "        harvard_square = Zonal()\n",
    "\n",
    "        harvard_square.load_layer(\n",
    "            layer_name='streets',\n",
    "            file_path=  test_case_folder + test_config.at[test_idx, 'Network_File']\n",
    "            )\n",
    "\n",
    "        harvard_square.load_layer(\n",
    "            layer_name=test_config.at[test_idx, 'Origin_Name'],\n",
    "            file_path= test_case_folder + test_config.at[test_idx, 'Origin_File']\n",
    "            )\n",
    "\n",
    "        harvard_square.load_layer(\n",
    "            layer_name=test_config.at[test_idx, 'Destination_Name'],\n",
    "            file_path= test_case_folder + test_config.at[test_idx, 'Destination_File']\n",
    "            )\n",
    "        \n",
    "\n",
    "        harvard_square.create_street_network(\n",
    "            source_layer='streets', \n",
    "            discard_redundant_edges=True,\n",
    "            split_redundant_edges=False,\n",
    "            node_snapping_tolerance=0.1,  # TODO: check for sensitivity... pick one as default snapping.\n",
    "            weight_attribute=test_config.at[test_idx, 'Network_Cost'] if test_config.at[test_idx, 'Network_Cost'] != \"Geometric\" else None\n",
    "        )\n",
    "\n",
    "        #print (f\"{harvard_square.network.edges.shape = }\")\n",
    "        #print (f\"{harvard_square.network.nodes.shape = }\")\n",
    "        #harvard_square.network.nodes,  harvard_square.network.edges = _discard_redundant_edges(harvard_square.network.nodes, harvard_square.network.edges)\n",
    "        #print (f\"{harvard_square.network.edges.shape = }\")\n",
    "        #print (f\"{harvard_square.network.nodes.shape = }\")\n",
    "\n",
    "        harvard_square.insert_node(\n",
    "            layer_name=test_config.at[test_idx, 'Origin_Name'], \n",
    "            label='origin', \n",
    "            weight_attribute=test_config.at[test_idx, 'Origin_Weight'] if test_config.at[test_idx, 'Origin_Weight'] != \"Count\" else None\n",
    "        )\n",
    "        harvard_square.insert_node(\n",
    "            layer_name=test_config.at[test_idx, 'Destination_Name'], \n",
    "            label='destination', \n",
    "            weight_attribute=test_config.at[test_idx, 'Destination_Weight'] if test_config.at[test_idx, 'Destination_Weight'] != \"Count\" else None\n",
    "        )\n",
    "\n",
    "        harvard_square.create_graph()\n",
    "\n",
    "        node_gdf = harvard_square.network.nodes\n",
    "        origin_gdf = node_gdf[node_gdf['type'] == 'origin']\n",
    "\n",
    "        harvard_square.network.nodes[\"original_weight\"] = harvard_square.network.nodes[\"weight\"]\n",
    "\n",
    "        harvard_square.network.turn_penalty_amount = test_config.at[test_idx, 'Turn_Penalty']\n",
    "        harvard_square.network.turn_threshold_degree = test_config.at[test_idx, 'Turn_Threshold']\n",
    "\n",
    "        if test_config.at[test_idx, 'Elastic_Weights']:\n",
    "            '''\n",
    "            harvard_square.network.nodes[\"weight\"] = harvard_square.network.nodes[\"original_weight\"]\n",
    "            get_elastic_weight(\n",
    "                harvard_square.network,\n",
    "                search_radius=test_config.at[test_idx, 'Radius'],\n",
    "                detour_ratio=test_config.at[test_idx, 'Detour'],\n",
    "                beta=test_config.at[test_idx, 'Beta'],\n",
    "                decay=True, #test_config.at[test_idx, 'Decay'],\n",
    "                #turn_penalty=test_config.at[test_idx, 'Turns'],\n",
    "                turn_penalty=False,\n",
    "            )\n",
    "            for o_idx in origin_gdf.index:\n",
    "                harvard_square.network.nodes.at[o_idx, 'weight'] =  harvard_square.network.nodes.at[o_idx, 'elastic_weight']\n",
    "            '''\n",
    "            continue\n",
    "        '''\n",
    "        return_dict = parallel_betweenness(\n",
    "            harvard_square.network,\n",
    "            search_radius=test_config.at[test_idx, 'Radius'],\n",
    "            detour_ratio=test_config.at[test_idx, 'Detour'],\n",
    "            decay=test_config.at[test_idx, 'Decay'], #if test['Elastic weights'] else True,\n",
    "            decay_method=test_config.at[test_idx, 'Decay_Mode'],  # \"power\", \"exponent\"\n",
    "            beta=test_config.at[test_idx, 'Beta'],\n",
    "            path_detour_penalty='equal', # \"equal\",  # \"power\", \"exponent\", \"equal\"\n",
    "            origin_weights=False if type(test_config.at[test_idx, 'Origin_Weight']) != str else True,\n",
    "            closest_destination=test_config.at[test_idx, 'Closest_Destination'],\n",
    "            destination_weights=False if type(test_config.at[test_idx, 'Destination_Weight']) != str  else True,    #or (test['Elastic weights'])\n",
    "            # perceived_distance=False,\n",
    "            num_cores=6,\n",
    "            light_graph=True,\n",
    "            turn_penalty=test_config.at[test_idx, 'Turns'],\n",
    "        )\n",
    "        \n",
    "        '''\n",
    "        harvard_square.network.max_chunck_size = 50\n",
    "        harvard_square.network.chunking_method = 'pizza_chunks' # ['no_chunking', 'cocentric-chunks', 'random_chunks', 'pizza_chunks']\n",
    "        return_dict = paralell_betweenness_exposure(\n",
    "            harvard_square,\n",
    "            search_radius=test_config.at[test_idx,'Radius'],\n",
    "            detour_ratio=test_config.at[test_idx,'Detour'],\n",
    "            decay=False if test_config.at[test_idx,'Elastic_Weights'] else test_config.at[test_idx,'Decay'],  # elastic weight already reduces origin weight factoring in decay. if this pairing uses elastic weights, don't decay again,\n",
    "            decay_method=test_config.at[test_idx,'Decay_Mode'],\n",
    "            beta=test_config.at[test_idx,'Beta'],\n",
    "            num_cores=3,\n",
    "            path_detour_penalty='equal', # \"power\" | \"exponent\" | \"equal\"\n",
    "            closest_destination=test_config.at[test_idx,'Closest_Destination'],\n",
    "            elastic_weight=test_config.at[test_idx,'Elastic_Weights'],\n",
    "            turn_penalty=test_config.at[test_idx,'Turns'],\n",
    "            path_exposure_attribute=None,\n",
    "            return_path_record=False, \n",
    "            destniation_cap=None\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        simulated_sum_of_flow = return_dict['edge_gdf']['betweenness'].sum()\n",
    "        test_flow = test_flows[test_config.at[test_idx, 'Flow_Name']].sum()\n",
    "\n",
    "\n",
    "        ## create segment level comparison\n",
    "        # creating connector lines\n",
    "\n",
    "        import shapely.geometry as geo\n",
    "        simulated_betweenness = return_dict['edge_gdf'][['betweenness', 'parent_street_id']].rename(columns={\"betweenness\": \"simulated_betweenness\"}).drop_duplicates(subset=['parent_street_id']).set_index(\"parent_street_id\")\n",
    "        simulated_betweenness = harvard_square.layers[\"streets\"].gdf[[\"geometry\", \"__GUID\"]].join(simulated_betweenness).set_index(\"__GUID\")\n",
    "\n",
    "        test_name = test_config.at[test_idx, 'Flow_Name']\n",
    "        test_betweenness = test_flows[['__GUID', test_name]].set_index(\"__GUID\").rename(columns = {test_name: \"test_flow\"})\n",
    "\n",
    "\n",
    "        comparison = simulated_betweenness.join(test_betweenness)\n",
    "        comparison[\"difference\"] = comparison[\"simulated_betweenness\"] - comparison[\"test_flow\"]\n",
    "        comparison[\"difference_pct\"] = abs(comparison[\"difference\"]) / comparison[\"simulated_betweenness\"] *100\n",
    "        # segment level error\n",
    "        sle = comparison[~comparison[\"difference_pct\"].isna()]['difference_pct']\n",
    "\n",
    "        \n",
    "        node_gdf = harvard_square.network.nodes\n",
    "        edge_gdf = harvard_square.network.edges\n",
    "\n",
    "\n",
    "        origin_nodes = node_gdf[node_gdf['type'] == 'origin']\n",
    "        '''\n",
    "        origin_layer = harvard_square.layers[test_config.at[test_idx, 'Origin_Name']].gdf\n",
    "        origin_joined = origin_layer.join(origin_nodes.set_index('source_id'),lsuffix='_origin')\n",
    "        origin_joined['connector_line'] = origin_joined.apply(lambda x:geo.LineString([x['geometry'], x[\"geometry_origin\"]]), axis=1)\n",
    "        origin_joined[\"geometry\"] = origin_joined['connector_line']\n",
    "\n",
    "\n",
    "        destination_layer = harvard_square.layers[test_config.at[test_idx, 'Destination_Name']].gdf\n",
    "        destination_nodes = node_gdf[node_gdf['type'] == 'destination']\n",
    "        destination_joined = destination_layer.join(destination_nodes.set_index('source_id'),lsuffix='_destination')\n",
    "        destination_joined['connector_line'] = destination_joined.apply(lambda x:geo.LineString([x['geometry'], x[\"geometry_destination\"]]), axis=1)\n",
    "        destination_joined[\"geometry\"] = destination_joined['connector_line']\n",
    "\n",
    "\n",
    "        #print (f\"{origin_nodes.shape = }\\t{destination_nodes.shape = }\")\n",
    "\n",
    "        streets = harvard_square.layers[\"streets\"].gdf \n",
    "        network_file = gpd.read_file(test_case_folder + test_config.at[test_idx, 'Network_File'], engine='pyogrio')\n",
    "\n",
    "\n",
    "        flow_difference = comparison[\n",
    "            ((comparison['test_flow' ] > 0) & (comparison['simulated_betweenness'] == 0)) | \n",
    "            ((comparison['test_flow' ] == 0) & (comparison['simulated_betweenness'] > 0))\n",
    "        ]\n",
    "        harvard_square.create_map(\n",
    "            [\n",
    "                #{'gdf': streets[streets[test_config.at[test_idx, 'Network_Cost']] > 0], 'color': [255, 255, 255], 'text': test_config.at[test_idx, 'Network_Cost']},\n",
    "                {'gdf': streets, 'color': [100, 100, 100], 'opacity': 0.1},\n",
    "                {'gdf': edge_gdf[edge_gdf['betweenness'] > 0], 'color': ['125, 125, 0'], 'text': 'betweenness', 'opacity': 0.2},\n",
    "                #{'gdf': comparison[abs(comparison[\"difference\"]) > 0.01], 'color_by_attribute': 'difference', 'color_method': 'gradient', 'text': 'difference'},\n",
    "                {'gdf': comparison[(comparison[\"difference_pct\"] >= 0.1) & (comparison[\"difference_pct\"] < 100)], 'color_by_attribute': 'difference_pct', 'color_method': 'gradient', 'text': 'difference_pct'},\n",
    "                {'gdf': edge_gdf[edge_gdf['snapped'] == True], 'color': [255, 0, 255], 'opacity': 0.2},\n",
    "                {'gdf': network_file[network_file[\"geometry\"].geom_type == 'Polygon'], 'color': [125, 0, 125], 'text': '__GUID'},\n",
    "                {'gdf': flow_difference, 'color': [255, 255, 0] , 'text': 'difference'},        \n",
    "                #{'gdf': comparison[comparison['difference'] != 0], 'color_by_attribute': 'difference', 'color_method': 'gradient', 'text': 'difference', 'opacity':  0.1},\n",
    "                {'gdf': origin_layer, 'color': [0, 0, 255]},\n",
    "                {'gdf': origin_joined[['geometry']], 'color': [0, 0, 255]},\n",
    "                {'gdf': destination_layer, 'color': [255, 0, 0]},\n",
    "                {'gdf': destination_joined[['geometry']], 'color': [255, 0, 0]},\n",
    "                {'gdf': harvard_square.network.nodes[['geometry', 'type', 'weight']].reset_index(), 'color': [255, 0, 255], 'text': 'id'},\n",
    "            ],\n",
    "            save_as=\"Test Cases\\\\\" + test_case + '\\\\'  + test_name + \"._difference_map.html\"\n",
    "        )\n",
    "        '''\n",
    "        \n",
    "        #print (test_config.loc[test_idx])\n",
    "        print (f\"{test_config.at[test_idx, 'Flow_Name'][:30]:30s} | {simulated_sum_of_flow:15.2f} | {test_flow:15.2f} | {simulated_sum_of_flow - test_flow:8.2f} | {1-(simulated_sum_of_flow - test_flow)/ test_flow:10.2%} | {sle.mean():7.4f}% | {sle.median():9.4f}% | {sle.max():7.4f}% | {sle[sle > 0.1].count():8} | {sle[sle > 1.0].count():8} | {sle[sle > 3.0].count():8} | {sle[sle > 5.0].count():8} | {time.time() - start: 10.5f}\")\n",
    "        #print (\"DOne Case...\")\n",
    "        #break\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping track of visited destinations\n",
    "test name                      | madina_flow_sum | Rhino_flow_sum  | sum_diff | sum_smlr_% | sle_mean | sle_median | sle_max  | sle>0.1% | sle>1.0% | sle>3.0% | sle>5.0% | time_spent\n",
    "_Betweenness1                  |          702.07 |          702.07 |    -0.00 |    100.00% |  0.0000% |    0.0000% |  0.0000% |        0 |        0 |        0 |        0 |    4.27237\n",
    "_Betweenness2                  |        19025.63 |        19025.63 |     0.00 |    100.00% |  0.0000% |    0.0000% |  0.0000% |        0 |        0 |        0 |        0 |    7.92910\n",
    "_Betweenness3                  |        19214.00 |        19214.00 |     0.00 |    100.00% |  0.0000% |    0.0000% |  0.0000% |        0 |        0 |        0 |        0 |   11.60755\n",
    "_Betweenness4                  |        20853.18 |        20853.18 |    -0.00 |    100.00% |  0.0000% |    0.0000% |  0.0000% |        0 |        0 |        0 |        0 |   15.20730\n",
    "Somerville_Bus_Subway_Geometri |          700.29 |          713.14 |   -12.84 |    101.80% |  2.3488% |    2.2893% |  5.0852% |      266 |      232 |       96 |        2 |   12.55345\n",
    "Somerville_Bus_Subway          |          730.95 |          743.95 |   -13.00 |    101.75% |  2.4117% |    2.2917% |  5.1912% |      285 |      251 |      103 |        8 |   25.87746\n",
    "Somerville_Homes_Subway        |       368786.93 |       389383.31 | -20596.38 |    105.29% |     inf% |    6.9536% |     inf% |     2640 |     2565 |     2355 |     1966 |  277.37418\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_layer</th>\n",
       "      <th>source_id</th>\n",
       "      <th>type</th>\n",
       "      <th>weight</th>\n",
       "      <th>degree</th>\n",
       "      <th>geometry</th>\n",
       "      <th>nearest_edge_id</th>\n",
       "      <th>edge_start_node</th>\n",
       "      <th>weight_to_start</th>\n",
       "      <th>edge_end_node</th>\n",
       "      <th>weight_to_end</th>\n",
       "      <th>original_weight</th>\n",
       "      <th>chunck_time</th>\n",
       "      <th>reach</th>\n",
       "      <th>destination_discovery_time</th>\n",
       "      <th>destination_prep_time</th>\n",
       "      <th>path_generation_time</th>\n",
       "      <th>chunck_count</th>\n",
       "      <th>memory_stalls</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12002</th>\n",
       "      <td>Homes</td>\n",
       "      <td>4583</td>\n",
       "      <td>origin</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (231917.747 904873.814)</td>\n",
       "      <td>4776.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>69.829693</td>\n",
       "      <td>772.0</td>\n",
       "      <td>163.640477</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>[0.011427640914916992]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011428</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13299</th>\n",
       "      <td>Homes</td>\n",
       "      <td>5880</td>\n",
       "      <td>origin</td>\n",
       "      <td>25.963800</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (230815.023 905079.012)</td>\n",
       "      <td>4419.0</td>\n",
       "      <td>3221.0</td>\n",
       "      <td>47.609317</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>22.319624</td>\n",
       "      <td>25.963800</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17207</th>\n",
       "      <td>Homes</td>\n",
       "      <td>9788</td>\n",
       "      <td>origin</td>\n",
       "      <td>3.510840</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (231723.700 905104.795)</td>\n",
       "      <td>4067.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>194.479460</td>\n",
       "      <td>5848.0</td>\n",
       "      <td>35.438606</td>\n",
       "      <td>3.510840</td>\n",
       "      <td>[0.01111602783203125]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.018538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30271</th>\n",
       "      <td>Homes</td>\n",
       "      <td>22852</td>\n",
       "      <td>origin</td>\n",
       "      <td>12.939200</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (235928.707 902676.981)</td>\n",
       "      <td>10078.0</td>\n",
       "      <td>2051.0</td>\n",
       "      <td>58.899262</td>\n",
       "      <td>3219.0</td>\n",
       "      <td>44.870730</td>\n",
       "      <td>12.939200</td>\n",
       "      <td>[0.010027170181274414]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14587</th>\n",
       "      <td>Homes</td>\n",
       "      <td>7168</td>\n",
       "      <td>origin</td>\n",
       "      <td>4.025810</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (231816.793 905152.732)</td>\n",
       "      <td>4120.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>110.310915</td>\n",
       "      <td>5937.0</td>\n",
       "      <td>111.246295</td>\n",
       "      <td>4.025810</td>\n",
       "      <td>[0.029735803604125977]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029736</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39102</th>\n",
       "      <td>Homes</td>\n",
       "      <td>31683</td>\n",
       "      <td>origin</td>\n",
       "      <td>4.560630</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (230716.082 905073.466)</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>1713.0</td>\n",
       "      <td>49.521505</td>\n",
       "      <td>4951.0</td>\n",
       "      <td>69.033394</td>\n",
       "      <td>4.560630</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19171</th>\n",
       "      <td>Homes</td>\n",
       "      <td>11752</td>\n",
       "      <td>origin</td>\n",
       "      <td>2.895500</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (231066.504 904946.712)</td>\n",
       "      <td>4745.0</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>26.173963</td>\n",
       "      <td>2416.0</td>\n",
       "      <td>37.564844</td>\n",
       "      <td>2.895500</td>\n",
       "      <td>[0.009996414184570312]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37093</th>\n",
       "      <td>Homes</td>\n",
       "      <td>29674</td>\n",
       "      <td>origin</td>\n",
       "      <td>5.213830</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (231002.108 904306.827)</td>\n",
       "      <td>393.0</td>\n",
       "      <td>2982.0</td>\n",
       "      <td>10.518509</td>\n",
       "      <td>2118.0</td>\n",
       "      <td>64.765304</td>\n",
       "      <td>5.213830</td>\n",
       "      <td>[0.0018138885498046875]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41709</th>\n",
       "      <td>Homes</td>\n",
       "      <td>34290</td>\n",
       "      <td>origin</td>\n",
       "      <td>3.279720</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (231056.671 904028.443)</td>\n",
       "      <td>397.0</td>\n",
       "      <td>1873.0</td>\n",
       "      <td>53.140186</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>58.328213</td>\n",
       "      <td>3.279720</td>\n",
       "      <td>[0.01000213623046875]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8663</th>\n",
       "      <td>Homes</td>\n",
       "      <td>1244</td>\n",
       "      <td>origin</td>\n",
       "      <td>0.703251</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (231360.530 904708.205)</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>35.805955</td>\n",
       "      <td>6433.0</td>\n",
       "      <td>113.444820</td>\n",
       "      <td>0.703251</td>\n",
       "      <td>[0.07650518417358398]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.006044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076505</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6008 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      source_layer  source_id    type     weight  degree  \\\n",
       "id                                                         \n",
       "12002        Homes       4583  origin   3.940000       0   \n",
       "13299        Homes       5880  origin  25.963800       0   \n",
       "17207        Homes       9788  origin   3.510840       0   \n",
       "30271        Homes      22852  origin  12.939200       0   \n",
       "14587        Homes       7168  origin   4.025810       0   \n",
       "...            ...        ...     ...        ...     ...   \n",
       "39102        Homes      31683  origin   4.560630       0   \n",
       "19171        Homes      11752  origin   2.895500       0   \n",
       "37093        Homes      29674  origin   5.213830       0   \n",
       "41709        Homes      34290  origin   3.279720       0   \n",
       "8663         Homes       1244  origin   0.703251       0   \n",
       "\n",
       "                            geometry  nearest_edge_id  edge_start_node  \\\n",
       "id                                                                       \n",
       "12002  POINT (231917.747 904873.814)           4776.0            375.0   \n",
       "13299  POINT (230815.023 905079.012)           4419.0           3221.0   \n",
       "17207  POINT (231723.700 905104.795)           4067.0            397.0   \n",
       "30271  POINT (235928.707 902676.981)          10078.0           2051.0   \n",
       "14587  POINT (231816.793 905152.732)           4120.0            451.0   \n",
       "...                              ...              ...              ...   \n",
       "39102  POINT (230716.082 905073.466)           1984.0           1713.0   \n",
       "19171  POINT (231066.504 904946.712)           4745.0           1938.0   \n",
       "37093  POINT (231002.108 904306.827)            393.0           2982.0   \n",
       "41709  POINT (231056.671 904028.443)            397.0           1873.0   \n",
       "8663   POINT (231360.530 904708.205)           5032.0           1178.0   \n",
       "\n",
       "       weight_to_start  edge_end_node  weight_to_end  original_weight  \\\n",
       "id                                                                      \n",
       "12002        69.829693          772.0     163.640477         3.940000   \n",
       "13299        47.609317         1217.0      22.319624        25.963800   \n",
       "17207       194.479460         5848.0      35.438606         3.510840   \n",
       "30271        58.899262         3219.0      44.870730        12.939200   \n",
       "14587       110.310915         5937.0     111.246295         4.025810   \n",
       "...                ...            ...            ...              ...   \n",
       "39102        49.521505         4951.0      69.033394         4.560630   \n",
       "19171        26.173963         2416.0      37.564844         2.895500   \n",
       "37093        10.518509         2118.0      64.765304         5.213830   \n",
       "41709        53.140186         1262.0      58.328213         3.279720   \n",
       "8663         35.805955         6433.0     113.444820         0.703251   \n",
       "\n",
       "                   chunck_time  reach  destination_discovery_time  \\\n",
       "id                                                                  \n",
       "12002   [0.011427640914916992]    1.0                    0.009997   \n",
       "13299                    [0.0]    1.0                    0.021284   \n",
       "17207    [0.01111602783203125]    1.0                    0.018538   \n",
       "30271   [0.010027170181274414]    1.0                    0.006911   \n",
       "14587   [0.029735803604125977]    1.0                    0.014991   \n",
       "...                        ...    ...                         ...   \n",
       "39102                    [0.0]    1.0                    0.011221   \n",
       "19171   [0.009996414184570312]    1.0                    0.010040   \n",
       "37093  [0.0018138885498046875]    1.0                    0.014700   \n",
       "41709    [0.01000213623046875]    1.0                    0.003446   \n",
       "8663     [0.07650518417358398]    2.0                    0.006044   \n",
       "\n",
       "       destination_prep_time  path_generation_time  chunck_count  \\\n",
       "id                                                                 \n",
       "12002                    0.0              0.011428           1.0   \n",
       "13299                    0.0              0.000000           1.0   \n",
       "17207                    0.0              0.011116           1.0   \n",
       "30271                    0.0              0.010027           1.0   \n",
       "14587                    0.0              0.029736           1.0   \n",
       "...                      ...                   ...           ...   \n",
       "39102                    0.0              0.000000           1.0   \n",
       "19171                    0.0              0.009996           1.0   \n",
       "37093                    0.0              0.001814           1.0   \n",
       "41709                    0.0              0.010002           1.0   \n",
       "8663                     0.0              0.076505           1.0   \n",
       "\n",
       "       memory_stalls  \n",
       "id                    \n",
       "12002            0.0  \n",
       "13299            0.0  \n",
       "17207            0.0  \n",
       "30271            0.0  \n",
       "14587            0.0  \n",
       "...              ...  \n",
       "39102            0.0  \n",
       "19171            0.0  \n",
       "37093            0.0  \n",
       "41709            0.0  \n",
       "8663             0.0  \n",
       "\n",
       "[6008 rows x 19 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_dict['origin_gdf'][~return_dict['origin_gdf']['chunck_time'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "\n",
    "px.scatter(\n",
    "    return_dict['origin_gdf'], \n",
    "    x='reach', \n",
    "    y='path_generation_time'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "def profile_new():\n",
    "    origin_gdf = origin_nodes\n",
    "    num_cores = 1\n",
    "    with mp.Manager() as manager:\n",
    "        #create aNDfill queue\n",
    "        origin_queue = manager.Queue()\n",
    "        for o_idx in origin_gdf.index[:]:\n",
    "            origin_queue.put(o_idx)\n",
    "        for core_index in range(num_cores):\n",
    "            origin_queue.put(\"done\")\n",
    "\n",
    "\n",
    "        return_dict = betweenness_exposure(\n",
    "            harvard_square,\n",
    "            core_index=1,\n",
    "            origin_queue=origin_queue,\n",
    "            #origins=origin_gdf.iloc[:1000],\n",
    "            search_radius=test_config.at[test_idx,'Radius'],\n",
    "            detour_ratio=test_config.at[test_idx,'Detour'],\n",
    "            decay=False if test_config.at[test_idx,'Elastic_Weights'] else test_config.at[test_idx,'Decay'],\n",
    "            beta=test_config.at[test_idx,'Beta'],\n",
    "            decay_method=test_config.at[test_idx,'Decay_Mode'],\n",
    "            path_detour_penalty='equal',\n",
    "            closest_destination=test_config.at[test_idx,'Closest_Destination'],\n",
    "            elastic_weight=test_config.at[test_idx,'Elastic_Weights'],\n",
    "            turn_penalty=test_config.at[test_idx,'Turns'],\n",
    "            path_exposure_attribute=None,\n",
    "            return_path_record=False, \n",
    "            destniation_cap=None\n",
    "    )\n",
    "    return return_dict\n",
    "x = profile_new()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "madina_env_latest_updates",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
