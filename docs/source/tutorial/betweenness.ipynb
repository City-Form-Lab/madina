{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Calculating Betweenness\n",
    "\n",
    "This notebook will walk you through the process of calculating betweenness values with the Madina\n",
    "package. It will read in geographic data as well as global parameters from a local directory, load\n",
    "the layers into a Zonal object, generate the geographic network, and run betweenness analysis\n",
    "on the given origin and destination layers, potentially with elastic weights.\n",
    "\n",
    "Please use this notebook as a template to create your own workflow, and feel free to change the\n",
    "behavior of the logger, or add any necessary preprocessings to the geographic layers.\n",
    "\n",
    "To run this notebook on your own data, please put it in a folder parallel to the `madina` subfolder\n",
    "under the repository as shown below. If you want to run the notebook elsewhere, remember to change\n",
    "the `sys.path.append(\"..\")` to append the parent folder of the `madina` subfolder to system path.\n",
    "```\n",
    "madina (the repository)\n",
    "|---madina\n",
    "|   |---all code for the package\n",
    "|---notebooks\n",
    "    |---this notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary packages\n",
    "\n",
    "The import is split into two sections: importing dependencies, and importing the Madina package.\n",
    "We recommend importing classes and functions from the Madina package directly instead of importing\n",
    "the Madina package as a whole. We also recommend that the functions are imported from local files\n",
    "for now, in order to avoid the troubles coming with installation and conflicts between conda and\n",
    "pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from shapely.ops import transform\n",
    "\n",
    "sys.path.append(\"../../..\")\n",
    "from madina.zonal.zonal import Layer\n",
    "from madina.zonal.zonal import Zonal\n",
    "from madina.una.betweenness import parallel_betweenness\n",
    "from madina.una.elastic import get_elastic_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Logger\n",
    "\n",
    "The Logger class provides a simple interface to show the users progress of the betweenness analysis,\n",
    "as well as to debug according to the intermediate results it saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger():\n",
    "    def __init__(self, output_folder):\n",
    "        self.output_folder = output_folder\n",
    "        self.start_time = datetime.now()\n",
    "        self.log_df = pd.DataFrame(\n",
    "            {\n",
    "                \"time\": pd.Series(dtype='datetime64[ns]'),\n",
    "                \"distance\": pd.Series(dtype=\"string\"),\n",
    "                \"tune_penalty\": pd.Series(dtype=\"string\"),\n",
    "                \"elastic_weight\": pd.Series(dtype=\"string\"),\n",
    "                \"origin\": pd.Series(dtype=\"string\"),\n",
    "                \"destination\": pd.Series(dtype=\"string\"),\n",
    "                \"event\": pd.Series(dtype=\"string\")\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def simulation_start(self, zone, network_weight_settings, turn_penalty_settings, elastic_weight_settings):\n",
    "        self.betweenness_record = zone.layers['streets'].gdf.copy(deep=True)\n",
    "        self.separate_simulation_records = {}\n",
    "        for network_weight in network_weight_settings:\n",
    "            self.separate_simulation_records[network_weight] = {}\n",
    "            for turn_penalty in turn_penalty_settings:\n",
    "                self.separate_simulation_records[network_weight][turn_penalty] = {}\n",
    "                for elastic_weight in elastic_weight_settings:\n",
    "                    self.separate_simulation_records[network_weight][turn_penalty][elastic_weight] = self.betweenness_record.copy(deep=True)\n",
    "\n",
    "    def log(self, input_dict):\n",
    "        input_dict[\"time\"] = datetime.now()\n",
    "        if self.log_df.shape[0] == 0:\n",
    "            print(f\"total time\\tseconds elapsed\\tdiatance method\\telastic_weight\\t{'origin':^15s}\\t{'destination':^15s}\\tevent\")\n",
    "            input_dict[\"seconds_elapsed\"] = 0\n",
    "            input_dict[\"cumulative_seconds\"] = 0\n",
    "        else:\n",
    "            time_elapsed = (input_dict[\"time\"] - self.log_df.iloc[-1][\"time\"]).seconds\n",
    "            input_dict[\"seconds_elapsed\"] = time_elapsed\n",
    "            input_dict[\"cumulative_seconds\"] = self.log_df[\"seconds_elapsed\"].sum() + time_elapsed\n",
    "\n",
    "        for column_name in self.log_df.columns:\n",
    "            if column_name not in input_dict:\n",
    "                input_dict[column_name] = \"---\"\n",
    "\n",
    "        self.log_df = pd.concat([self.log_df, pd.DataFrame([input_dict])], ignore_index=True)\n",
    "        print(\n",
    "            f\"{input_dict['cumulative_seconds']:6.4f}\\t\\t\"\n",
    "            f\"{input_dict['seconds_elapsed']}\\t\\t\\t\\t\"\n",
    "            f\"{input_dict['distance']}\\t\\t\"\n",
    "            f\"{input_dict['tune_penalty']}\\t\\t\"\n",
    "            f\"{input_dict['elastic_weight']}\\t\\t\"\n",
    "            f\"{input_dict['origin']:^15s}\\t\"\n",
    "            f\"{input_dict['destination']:^15s}\\t\"\n",
    "            f\"{input_dict['event']}\"\n",
    "        )\n",
    "\n",
    "    def pairing_end(self, shaqra: Zonal, pairing, network_weight, turn_penalty, elastic_weight):\n",
    "        \"\"\"\n",
    "        This function should be called whenever one round of betweenness analysis concludes.\n",
    "        It will save the betweenness results for the current round into a subfolder of the output\n",
    "        folder designated by the Zonal class, as well as logging the execution times.\n",
    "        \"\"\"\n",
    "        # creating a folder for output\n",
    "        pairing_folder = self.output_folder + f\"{network_weight}\\\\{'with_turns' if turn_penalty else 'no_turns'}\\\\{'elastic_weight' if elastic_weight else 'unadjusted_weight'}\\\\O({pairing['Origin_Name']})_D({pairing['Destination_Name']})\\\\\"\n",
    "        Path(pairing_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        street_gdf = shaqra.layers[\"streets\"].gdf\n",
    "        node_gdf = shaqra.network.nodes\n",
    "        origin_gdf = node_gdf[node_gdf[\"type\"] == \"origin\"]\n",
    "        destination_gdf = node_gdf[node_gdf[\"type\"] == \"destination\"]\n",
    "        edge_gdf = shaqra.network.edges\n",
    "        edge_gdf[\"width\"] = edge_gdf[\"betweenness\"] / edge_gdf[\"betweenness\"].mean() + 0.25\n",
    "\n",
    "\n",
    "        self.betweenness_record = self.betweenness_record.join(\n",
    "            edge_gdf[['parent_street_id', 'betweenness']].set_index('parent_street_id')).rename(\n",
    "            columns={\n",
    "                \"betweenness\": f\"{network_weight}_{'with_turns' if turn_penalty else 'no_turns'}_{'elastic_weight' if elastic_weight else 'unadjusted_weight'}_{pairing['Between_Name']}\"})\n",
    "\n",
    "        self.separate_simulation_records[network_weight][turn_penalty][elastic_weight] = \\\n",
    "        self.separate_simulation_records[network_weight][turn_penalty][elastic_weight].join(\n",
    "            edge_gdf[['parent_street_id', 'betweenness']].set_index('parent_street_id')).rename(\n",
    "            columns={\n",
    "                \"betweenness\": f\"{network_weight}_{'with_turns' if turn_penalty else 'no_turns'}_{'elastic_weight' if elastic_weight else 'unadjusted_weight'}_{pairing['Between_Name']}\"})\n",
    "\n",
    "        save_results = \\\n",
    "            edge_gdf.set_index('parent_street_id').join(street_gdf, lsuffix='_from_edge')[\n",
    "                # , rsuffix='_from_streets'\n",
    "                [\"betweenness\", \"__GUID\", \"geometry\"]]\n",
    "        save_results = save_results.rename(\n",
    "            columns={\n",
    "                \"betweenness\": f\"{network_weight}_{'with_turns' if turn_penalty else 'no_turns'}_{'elastic_weight' if elastic_weight else 'unadjusted_weight'}_{pairing['Between_Name']}\"})\n",
    "\n",
    "        save_results.to_csv(pairing_folder + \"flows.csv\")\n",
    "        # save_results.to_file(pairing_folder + \"flows.geojson\", driver=\"GeoJSON\")\n",
    "        self.betweenness_record.to_csv(pairing_folder + \"betweenness_record_so_far.csv\")\n",
    "        self.separate_simulation_records[network_weight][turn_penalty][elastic_weight].to_csv(\n",
    "            pairing_folder + \"simulation_record_so_far.csv\")\n",
    "\n",
    "        self.log_df.to_csv(pairing_folder + \"time_log.csv\")\n",
    "\n",
    "        self.log({\n",
    "            \"origin\": pairing[\"Origin_Name\"],\n",
    "            \"destination\": pairing[\"Destination_Name\"],\n",
    "            \"event\": \"Output saved\",\n",
    "            \"distance\": network_weight,\n",
    "            \"tune_penalty\": turn_penalty,\n",
    "            \"elastic_weight\": elastic_weight})\n",
    "\n",
    "    def simulation_end(self, network_weight_settings, turn_penalty_settings, elastic_weight_settings):\n",
    "        self.betweenness_record.to_csv(self.output_folder + \"betweenness_record.csv\")\n",
    "        #self.betweenness_record.to_file(self.output_folder + \"street_network_betweenness_record.geojson\", driver=\"GeoJSON\")\n",
    "        for network_weight in network_weight_settings:\n",
    "            for turn_penalty in turn_penalty_settings:\n",
    "                for elastic_weight in elastic_weight_settings:\n",
    "                    pairing_folder = self.output_folder + f\"{network_weight}\\\\{'with_turns' if turn_penalty else 'no_turns'}\\\\{'elastic_weight' if elastic_weight else 'unadjusted_weight'}\\\\\"\n",
    "                    self.separate_simulation_records[network_weight][turn_penalty][elastic_weight].to_csv(pairing_folder+\"betweenness_record.csv\")\n",
    "        self.log({\"event\": \"All DONE.\"})\n",
    "        self.log_df.to_csv(self.output_folder + \"time_log.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the workflow\n",
    "\n",
    "The function below defines the entire workflow of betweenness analysis, from data loading to\n",
    "saving the calculated flows. See comments for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def betweenness_flow_simulation(\n",
    "        city_name=\"Somerville\",\n",
    "        data_folder=None,\n",
    "        output_folder=None,\n",
    "        pairings_file=\"Pairings.csv\",\n",
    "        network_weight_settings = [\"Perceived\", \"Geometric\"],\n",
    "        turn_penalty_settings = [False, True],\n",
    "        elastic_weight_settings = [False, True],\n",
    "        num_cores=8,\n",
    "        turn_threshold_degree=45,\n",
    "        turn_penalty_amount=30,\n",
    "        impose_crs=None\n",
    "    ):\n",
    "    # Find the data folder and output folder according to user inputs.\n",
    "    if data_folder is None:\n",
    "        data_folder = \"Cities\\\\\"+city_name+\"\\\\Data\\\\\"\n",
    "    if output_folder is None:\n",
    "        start_time = datetime.now()\n",
    "        output_folder = f\"Cities\\\\{city_name}\\\\Simulations\\\\{start_time.year}_{start_time.month:02d}_{start_time.day:02d}_{start_time.hour:02d}_{start_time.minute:02d}\\\\\"\n",
    "\n",
    "    # Initializing the Logger\n",
    "    logger=Logger(output_folder)\n",
    "    logger.log({\"event\": \"beginning\"})\n",
    "\n",
    "    # Reading the pairings file, which defines all origin-destination pairs whose betweenness is\n",
    "    # to be analyzed\n",
    "    pairings = gpd.read_file(data_folder + pairings_file)\n",
    "\n",
    "    # Initializing the Zonal object\n",
    "    zonal = Zonal()\n",
    "    if impose_crs is not None:\n",
    "        zonal = Zonal(projected_crs=impose_crs)\n",
    "\n",
    "    # Loading the network layer from the file designated in the pairings file\n",
    "    zonal.load_layer(\n",
    "        layer_name='streets',\n",
    "        file_path=data_folder +  pairings.at[0, \"Network_File\"]\n",
    "    )\n",
    "    if impose_crs is not None:\n",
    "        zonal.layers[\"streets\"] = Layer(\n",
    "            label=\"streets\",\n",
    "            gdf=gpd.read_file(data_folder +  pairings.at[0, \"Network_File\"]).set_crs(impose_crs, allow_override=True),\n",
    "            show=True,\n",
    "            original_crs=impose_crs,\n",
    "            file_path=(data_folder + pairings.at[0, \"Network_File\"])\n",
    "        )\n",
    "\n",
    "    # Cleaning the network layer\n",
    "    geometry_gdf = zonal.layers[\"streets\"].gdf\n",
    "    polygon_idxs = geometry_gdf[geometry_gdf[\"geometry\"].geom_type == \"Polygon\"].index\n",
    "    geometry_gdf.loc[polygon_idxs,\"geometry\"] = geometry_gdf.loc[polygon_idxs, \"geometry\"].exterior\n",
    "    zonal.layers[\"streets\"].gdf = geometry_gdf\n",
    "\n",
    "    if zonal.layers[\"streets\"].gdf.has_z.any():\n",
    "        def _to_2d(x, y, z):\n",
    "            return tuple(filter(None, [x, y]))\n",
    "        zonal.layers[\"streets\"].gdf[\"geometry\"] = zonal.layers[\"streets\"].gdf[\n",
    "            \"geometry\"].apply(lambda s: transform(_to_2d, s))\n",
    "\n",
    "    if (zonal.layers[\"streets\"].gdf.geometry.geom_type == \"MultiLineString\").all():\n",
    "        zonal.layers[\"streets\"].gdf[\"geometry\"] = zonal.layers[\"streets\"].gdf[\n",
    "            \"geometry\"].apply(lambda s: s.geoms[0])\n",
    "\n",
    "    print(f'streets\\t{zonal.layers[\"streets\"].gdf.crs}')\n",
    "\n",
    "    logger.simulation_start(zonal, network_weight_settings, turn_penalty_settings, elastic_weight_settings)\n",
    "\n",
    "    # Setting up a street network\n",
    "    zonal.create_street_network(\n",
    "        source_layer=\"streets\",\n",
    "        node_snapping_tolerance=1,\n",
    "        weight_attribute=None if \"Perceived\" not in network_weight_settings else pairings.at[0, \"Network_Cost\"],\n",
    "        discard_redundant_edges=True,\n",
    "        turn_threshold_degree=turn_threshold_degree,\n",
    "        turn_penalty_amount=turn_penalty_amount\n",
    "        )\n",
    "    # This is to re-set the origins and destinations before any new iteration.\n",
    "    clean_node_gdf = zonal.network.nodes.copy(deep=True)\n",
    "\n",
    "    # preparing percieved and geometric weights...\n",
    "    perceived_network_weight = zonal.network.edges[\"weight\"]\n",
    "    perceived_network_weight = perceived_network_weight.apply(lambda x: max(1, x))\n",
    "    geometric_network_weight = zonal.network.edges[\"geometry\"].length\n",
    "\n",
    "    logger.log({\"event\": \"Network topology created.\"})\n",
    "\n",
    "    for idx, pairing in pairings.iterrows():\n",
    "        # Begin the execution of one O-D pair designated in the pairings file\n",
    "        if pairing[\"Origin_Name\"] not in zonal.layers:\n",
    "            # Loading the origin layer if it is not already loaded.\n",
    "            zonal.load_layer(\n",
    "                layer_name=pairing[\"Origin_Name\"],\n",
    "                file_path=data_folder + pairing[\"Origin_File\"]\n",
    "            )\n",
    "            print(f\"{pairing['Origin_Name']}\\t{zonal.layers[pairing['Origin_Name']].gdf.crs}\")\n",
    "            if (impose_crs is not None) and (zonal.layers[pairing[\"Origin_Name\"]].gdf.crs != impose_crs):\n",
    "                print(\"Imposing CRS\", impose_crs)\n",
    "                zonal.layers[pairing[\"Origin_Name\"]] = Layer(\n",
    "                    label=pairing[\"Origin_Name\"],\n",
    "                    gdf=gpd.read_file(data_folder + pairing[\"Origin_File\"]).set_crs(impose_crs, allow_override=True),\n",
    "                    show=True,\n",
    "                    original_crs=impose_crs,\n",
    "                    file_path=(data_folder + pairing[\"Origin_File\"])\n",
    "                )\n",
    "\n",
    "            print(f\"{pairing['Origin_Name']}\\t{zonal.layers[pairing['Origin_Name']].gdf.crs}\\t{zonal.layers[pairing['Origin_Name']].crs}\")\n",
    "\n",
    "\n",
    "            # Data Cleaning\n",
    "            if zonal.layers[pairing[\"Origin_Name\"]].gdf.has_z.any():\n",
    "                zonal.layers[pairing[\"Origin_Name\"]] = Layer(\n",
    "                    label=pairing[\"Origin_Name\"],\n",
    "                    gdf=zonal.layers[pairing[\"Origin_File\"]].gdf[\"geometry\"].apply(lambda s: transform(_to_2d, s)),\n",
    "                    show=True,\n",
    "                    original_crs=impose_crs,\n",
    "                    file_path=(data_folder + pairing[\"Origin_File\"])\n",
    "                )\n",
    "\n",
    "        if pairing[\"Destination_Name\"] not in zonal.layers:\n",
    "            # Loading the destination layer if it is not already loaded.\n",
    "            zonal.load_layer(\n",
    "                layer_name=pairing[\"Destination_Name\"],\n",
    "                file_path=data_folder + pairing[\"Destination_File\"]\n",
    "            )\n",
    "            if (impose_crs is not None) and (zonal.layers[pairing[\"Destination_Name\"]].gdf.crs != impose_crs):\n",
    "                zonal.layers[pairing[\"Destination_Name\"]] = Layer(\n",
    "                    label=pairing[\"Destination_Name\"],\n",
    "                    gdf=gpd.read_file(data_folder + pairing[\"Destination_File\"]).set_crs(impose_crs, allow_override=True),\n",
    "                    show=True,\n",
    "                    original_crs=impose_crs,\n",
    "                    file_path=(data_folder + pairing[\"Destination_File\"])\n",
    "                )\n",
    "            # Data Cleaning\n",
    "            if zonal.layers[pairing[\"Destination_Name\"]].gdf.has_z.any():\n",
    "                zonal.layers[pairing[\"Destination_Name\"]] = Layer(\n",
    "                    label=pairing[\"Destination_Name\"],\n",
    "                    gdf=zonal.layers[pairing[\"Destination_File\"]].gdf[\"geometry\"].apply(lambda s: transform(_to_2d, s)),\n",
    "                    show=True,\n",
    "                    original_crs=impose_crs,\n",
    "                    file_path=(data_folder + pairing[\"Destination_File\"])\n",
    "                )\n",
    "        \n",
    "        print(f\"{pairing['Origin_Name']}\\t{zonal.layers[pairing['Origin_Name']].gdf.crs}\")\n",
    "        print(f\"{pairing['Destination_Name']}\\t{zonal.layers[pairing['Destination_Name']].gdf.crs}\")\n",
    "        print(f\"Zonal Edge Count: {len(zonal.network.edges)}\")\n",
    "\n",
    "        # making sure to clear any existing origins and destinations before adding new ones.\n",
    "        zonal.network.nodes = clean_node_gdf.copy(deep=True)\n",
    "\n",
    "        # iterating over the three betweenness calculation options: network weight, turn penalty,\n",
    "        # and elastic weight\n",
    "        for network_weight in network_weight_settings:\n",
    "\n",
    "            # setting the proper network_weight\n",
    "            if network_weight == \"Perceived\":\n",
    "                zonal.network.nodes[\"weight\"] = perceived_network_weight\n",
    "            elif network_weight == \"Geometric\":\n",
    "                zonal.network.edges[\"weight\"] = geometric_network_weight\n",
    "\n",
    "            # Insert the origin and destination nodes into the network\n",
    "            zonal.insert_node(\n",
    "                label=\"origin\",\n",
    "                layer_name=pairing[\"Origin_Name\"],\n",
    "                weight_attribute=pairing[\"Origin_Weight\"] if pairing[\"Origin_Weight\"] != \"Count\" else None,\n",
    "            )\n",
    "\n",
    "            zonal.insert_node(\n",
    "                label=\"destination\",\n",
    "                layer_name=pairing[\"Destination_Name\"],\n",
    "                weight_attribute=pairing[\"Destination_Weight\"] if pairing[\"Destination_Weight\"] != \"Count\" else None,\n",
    "            )\n",
    "\n",
    "            inelastic_weight = zonal.network.nodes['weight']\n",
    "\n",
    "\n",
    "            logger.log({\n",
    "                \"origin\": pairing[\"Origin_Name\"],\n",
    "                \"destination\": pairing[\"Destination_Name\"],\n",
    "                \"event\": \"Origins and Destinations prepared.\"\n",
    "                })\n",
    "\n",
    "            zonal.create_graph(light_graph=True, od_graph=True)\n",
    "\n",
    "            logger.log({\n",
    "                \"origin\": pairing[\"Origin_Name\"],\n",
    "                \"destination\": pairing[\"Destination_Name\"],\n",
    "                \"event\": \"Light and dense graphs prepared.\"\n",
    "                })\n",
    "\n",
    "            for turn_penalty in turn_penalty_settings:\n",
    "                for elastic_weight in elastic_weight_settings:\n",
    "                    # The order of these is important, as the weight is overriden by\n",
    "                    # elastic weight as there is no clean way to update weight for now.\n",
    "                    if elastic_weight:\n",
    "                        # Calculate the elastic weight\n",
    "                        get_elastic_weight(\n",
    "                            zonal.network,\n",
    "                            search_radius=800,\n",
    "                            detour_ratio=0.002,\n",
    "                            beta=0.002,\n",
    "                            decay=True,\n",
    "                            turn_penalty=turn_penalty,\n",
    "                            retained_d_idxs=None\n",
    "                            )\n",
    "\n",
    "                        logger.log({\n",
    "                            \"origin\": pairing[\"Origin_Name\"],\n",
    "                            \"destination\": pairing[\"Destination_Name\"],\n",
    "                            \"event\": \"Elastic Weights generated.\",\n",
    "                            \"distance\": network_weight, \"tune_penalty\": turn_penalty,\n",
    "                            \"elastic_weight\": elastic_weight})\n",
    "                    else:\n",
    "                        zonal.network.nodes['weight'] = inelastic_weight\n",
    "\n",
    "                    # Run the betwenness analysis\n",
    "\n",
    "                    node_gdf = zonal.network.nodes\n",
    "                    origin_gdf = node_gdf[node_gdf[\"type\"] == \"origin\"]\n",
    "\n",
    "                    num_cores = min(origin_gdf.shape[0], num_cores)\n",
    "                    betweenness_output = parallel_betweenness(\n",
    "                        zonal.network,\n",
    "                        search_radius=float(pairing[\"Radius\"]),\n",
    "                        detour_ratio=float(pairing[\"Detour\"]),\n",
    "                        decay=False if elastic_weight else True,\n",
    "                        decay_method=\"exponent\",  # \"power\", \"exponent\"\n",
    "                        beta=float(pairing[\"Beta\"]),\n",
    "                        path_detour_penalty=\"equal\",  # \"power\", \"exponent\", \"equal\"\n",
    "                        origin_weights=True,\n",
    "                        closest_destination=False,\n",
    "                        destination_weights=True,\n",
    "                        num_cores=num_cores,\n",
    "                        turn_penalty=turn_penalty,\n",
    "                        rertain_expensive_data=False if elastic_weight else True,\n",
    "                        retained_d_idxs=None,\n",
    "                        retained_paths=None,\n",
    "                        retained_distances=None,\n",
    "                    )\n",
    "\n",
    "                    if not elastic_weight:\n",
    "                        retained_d_idxs = betweenness_output[\"retained_d_idxs\"]\n",
    "\n",
    "                    logger.log({\n",
    "                        \"origin\": pairing[\"Origin_Name\"],\n",
    "                        \"destination\": pairing[\"Destination_Name\"],\n",
    "                        \"event\": \"Betweenness estimated.\",\n",
    "                        \"distance\": network_weight,\n",
    "                        \"tune_penalty\": turn_penalty,\n",
    "                        \"elastic_weight\": elastic_weight})\n",
    "                    logger.pairing_end(zonal, pairing, network_weight, turn_penalty, elastic_weight)\n",
    "                    \n",
    "    logger.simulation_end(network_weight_settings, turn_penalty_settings, elastic_weight_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the workflow\n",
    "\n",
    "The cell below shows one sample of running the betweenness analysis on the city of Somerville in\n",
    "Massachusetts, USA. The data folder used can be downloaded from here: TODO: Dropbox link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time\tseconds elapsed\tdiatance method\telastic_weight\t    origin     \t  destination  \tevent\n",
      "0.0000\t\t0\t\t\t\t---\t\t---\t\t---\t\t      ---      \t      ---      \tbeginning\n",
      "streets\tepsg:26986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\56830\\OneDrive - Massachusetts Institute of Technology\\UROPs\\UNA\\madina\\docs\\source\\tutorial\\../../..\\madina\\zonal\\network_utils.py:171: FutureWarning: The `query_bulk()` method is deprecated and will be removed in GeoPandas 1.0. You can use the `query()` method instead.\n",
      "  matching = point_geometries.sindex.query_bulk(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.0000\t\t21\t\t\t\t---\t\t---\t\t---\t\t      ---      \t      ---      \tNetwork topology created.\n",
      "Bus\tEPSG:26986\n",
      "Bus\tEPSG:26986\tEPSG:26986\n",
      "Bus\tEPSG:26986\n",
      "Subway\tEPSG:26986\n",
      "Zonal Edge Count: 10122\n",
      "21.0000\t\t0\t\t\t\t---\t\t---\t\t---\t\t      Bus      \t    Subway     \tOrigins and Destinations prepared.\n",
      "22.0000\t\t1\t\t\t\t---\t\t---\t\t---\t\t      Bus      \t    Subway     \tLight and dense graphs prepared.\n",
      "-------------------------------------------\n",
      "All cores done in 7.65\n",
      "-------------------------------------------\n",
      "29.0000\t\t7\t\t\t\tGeometric\t\tTrue\t\tFalse\t\t      Bus      \t    Subway     \tBetweenness estimated.\n",
      "29.0000\t\t0\t\t\t\tGeometric\t\tTrue\t\tFalse\t\t      Bus      \t    Subway     \tOutput saved\n",
      "Home\tEPSG:26986\n",
      "Home\tEPSG:26986\tEPSG:26986\n",
      "Home\tEPSG:26986\n",
      "Subway\tEPSG:26986\n",
      "Zonal Edge Count: 10122\n",
      "31.0000\t\t2\t\t\t\t---\t\t---\t\t---\t\t     Home      \t    Subway     \tOrigins and Destinations prepared.\n",
      "47.0000\t\t16\t\t\t\t---\t\t---\t\t---\t\t     Home      \t    Subway     \tLight and dense graphs prepared.\n",
      "-------------------------------------------\n",
      "All cores done in 288.91\n",
      "-------------------------------------------\n",
      "336.0000\t\t289\t\t\t\tGeometric\t\tTrue\t\tFalse\t\t     Home      \t    Subway     \tBetweenness estimated.\n",
      "337.0000\t\t1\t\t\t\tGeometric\t\tTrue\t\tFalse\t\t     Home      \t    Subway     \tOutput saved\n",
      "337.0000\t\t0\t\t\t\t---\t\t---\t\t---\t\t      ---      \t      ---      \tAll DONE.\n"
     ]
    }
   ],
   "source": [
    "betweenness_flow_simulation(\n",
    "    city_name=\"Somerville\",\n",
    "    data_folder=f'..\\\\..\\\\..\\\\test_ipynb\\\\Cities\\\\Somerville\\\\Data\\\\',\n",
    "    pairings_file=\"Pairings.csv\",\n",
    "    network_weight_settings=[\"Geometric\"],          # [\"Perceived\", \"Geometric\"],\n",
    "    turn_penalty_settings=[True],                   # [False, True]\n",
    "    elastic_weight_settings=[False],          # [False, True]\n",
    "    num_cores=20,\n",
    "    turn_threshold_degree=45,\n",
    "    turn_penalty_amount=62.3,\n",
    "    impose_crs='epsg:26986'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
