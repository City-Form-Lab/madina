{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Expanding Madina\n",
    "## Goals\n",
    "* Implementing a betweenness flow sumulation function that just can be called from a zonal object with minimal parameters\n",
    "* implementing a dunction that takews count data and outputs a list of statistical models and thwir interporetation\n",
    "* set up a complete docstring template that's compliant and complete..\n",
    "* use code to run sommerville, run stats and interpret\n",
    "* publish the docstring on cityformlab.mit.edu or on github.com\n",
    "* use code to runn Beirut, interpret results\n",
    "* use mofel to run Melbourn, NYC,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from shapely.ops import transform\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from madina.zonal.zonal import Layer\n",
    "from madina.zonal.zonal import Zonal\n",
    "from madina.una.betweenness import parallel_betweenness\n",
    "from madina.una.elastic import get_elastic_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.24.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.13.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shapely\n",
    "shapely.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger():\n",
    "    def __init__(self, output_folder):\n",
    "        self.output_folder = output_folder\n",
    "        self.start_time = datetime.now()\n",
    "        self.log_df = pd.DataFrame(\n",
    "            {\n",
    "                \"time\": pd.Series(dtype='datetime64[ns]'),\n",
    "                \"distance\": pd.Series(dtype=\"string\"),\n",
    "                \"tune_penalty\": pd.Series(dtype=\"string\"),\n",
    "                \"elastic_weight\": pd.Series(dtype=\"string\"),\n",
    "                \"origin\": pd.Series(dtype=\"string\"),\n",
    "                \"destination\": pd.Series(dtype=\"string\"),\n",
    "                \"event\": pd.Series(dtype=\"string\")\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def simulation_start(self, zone, network_weight_settings, turn_penalty_settings, elastic_weight_settings):\n",
    "        ##-------------------------------------------------------------------------------------------------------------< Betweenness Recode...\n",
    "        self.betweenness_record = zone.layers['streets'].gdf.copy(deep=True)\n",
    "        self.separate_simulation_records = {}\n",
    "        for network_weight in network_weight_settings:\n",
    "            self.separate_simulation_records[network_weight] = {}\n",
    "            for turn_penalty in turn_penalty_settings:\n",
    "                self.separate_simulation_records[network_weight][turn_penalty] = {}\n",
    "                for elastic_weight in elastic_weight_settings:\n",
    "                    self.separate_simulation_records[network_weight][turn_penalty][elastic_weight] = self.betweenness_record.copy(deep=True)\n",
    "\n",
    "    def log(self, input_dict):\n",
    "        input_dict[\"time\"] = datetime.now()\n",
    "        if self.log_df.shape[0] == 0:\n",
    "            print(f\"total time\\tseconds elapsed\\tdiatance method\\telastic_weight\\t{'origin':^15s}\\t{'destination':^15s}\\tevent\")\n",
    "            input_dict[\"seconds_elapsed\"] = 0\n",
    "            input_dict[\"cumulative_seconds\"] = 0\n",
    "        else:\n",
    "            time_elapsed = (input_dict[\"time\"] - self.log_df.iloc[-1][\"time\"]).seconds\n",
    "            input_dict[\"seconds_elapsed\"] = time_elapsed\n",
    "            input_dict[\"cumulative_seconds\"] = self.log_df[\"seconds_elapsed\"].sum() + time_elapsed\n",
    "\n",
    "        for column_name in self.log_df.columns:\n",
    "            if column_name not in input_dict:\n",
    "                input_dict[column_name] = \"---\"\n",
    "\n",
    "        self.log_df = pd.concat([self.log_df, pd.DataFrame([input_dict])], ignore_index=True)\n",
    "        print(\n",
    "            f\"{input_dict['cumulative_seconds']:6.4f}\\t\\t\"\n",
    "            f\"{input_dict['seconds_elapsed']}\\t\\t\\t\\t\"\n",
    "            f\"{input_dict['distance']}\\t\\t\"\n",
    "            f\"{input_dict['tune_penalty']}\\t\\t\"\n",
    "            f\"{input_dict['elastic_weight']}\\t\\t\"\n",
    "            f\"{input_dict['origin']:^15s}\\t\"\n",
    "            f\"{input_dict['destination']:^15s}\\t\"\n",
    "            f\"{input_dict['event']}\"\n",
    "        )\n",
    "\n",
    "    def pairing_end(self, shaqra: Zonal, pairing, network_weight, turn_penalty, elastic_weight):\n",
    "        # creating a folder for output\n",
    "        pairing_folder = self.output_folder + f\"{network_weight}\\\\{'with_turns' if turn_penalty else 'no_turns'}\\\\{'elastic_weight' if elastic_weight else 'unadjusted_weight'}\\\\O({pairing['Origin_Name']})_D({pairing['Destination_Name']})\\\\\"\n",
    "        Path(pairing_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        street_gdf = shaqra.layers[\"streets\"].gdf\n",
    "        node_gdf = shaqra.network.nodes\n",
    "        origin_gdf = node_gdf[node_gdf[\"type\"] == \"origin\"]\n",
    "        destination_gdf = node_gdf[node_gdf[\"type\"] == \"destination\"]\n",
    "        edge_gdf = shaqra.network.edges\n",
    "        edge_gdf[\"width\"] = edge_gdf[\"betweenness\"] / edge_gdf[\"betweenness\"].mean() + 0.25\n",
    "\n",
    "\n",
    "        self.betweenness_record = self.betweenness_record.join(\n",
    "            edge_gdf[['parent_street_id', 'betweenness']].set_index('parent_street_id')).rename(\n",
    "            columns={\n",
    "                \"betweenness\": f\"{network_weight}_{'with_turns' if turn_penalty else 'no_turns'}_{'elastic_weight' if elastic_weight else 'unadjusted_weight'}_{pairing['Between_Name']}\"})\n",
    "\n",
    "        self.separate_simulation_records[network_weight][turn_penalty][elastic_weight] = \\\n",
    "        self.separate_simulation_records[network_weight][turn_penalty][elastic_weight].join(\n",
    "            edge_gdf[['parent_street_id', 'betweenness']].set_index('parent_street_id')).rename(\n",
    "            columns={\n",
    "                \"betweenness\": f\"{network_weight}_{'with_turns' if turn_penalty else 'no_turns'}_{'elastic_weight' if elastic_weight else 'unadjusted_weight'}_{pairing['Between_Name']}\"})\n",
    "\n",
    "        save_results = \\\n",
    "            edge_gdf.set_index('parent_street_id').join(street_gdf, lsuffix='_from_edge')[\n",
    "                # , rsuffix='_from_streets'\n",
    "                [\"betweenness\", \"__GUID\", \"geometry\"]]\n",
    "        save_results = save_results.rename(\n",
    "            columns={\n",
    "                \"betweenness\": f\"{network_weight}_{'with_turns' if turn_penalty else 'no_turns'}_{'elastic_weight' if elastic_weight else 'unadjusted_weight'}_{pairing['Between_Name']}\"})\n",
    "\n",
    "        save_results.to_csv(pairing_folder + \"flows.csv\")\n",
    "        # save_results.to_file(pairing_folder + \"flows.geojson\", driver=\"GeoJSON\")\n",
    "        self.betweenness_record.to_csv(pairing_folder + \"betweenness_record_so_far.csv\")\n",
    "        self.separate_simulation_records[network_weight][turn_penalty][elastic_weight].to_csv(\n",
    "            pairing_folder + \"simulation_record_so_far.csv\")\n",
    "\n",
    "        self.log_df.to_csv(pairing_folder + \"time_log.csv\")\n",
    "\n",
    "        self.log({\n",
    "            \"origin\": pairing[\"Origin_Name\"],\n",
    "            \"destination\": pairing[\"Destination_Name\"],\n",
    "            \"event\": \"Output saved\",\n",
    "            \"distance\": network_weight,\n",
    "            \"tune_penalty\": turn_penalty,\n",
    "            \"elastic_weight\": elastic_weight})\n",
    "\n",
    "    def simulation_end(self, network_weight_settings, turn_penalty_settings, elastic_weight_settings):\n",
    "        self.betweenness_record.to_csv(self.output_folder + \"betweenness_record.csv\")\n",
    "        #self.betweenness_record.to_file(self.output_folder + \"street_network_betweenness_record.geojson\", driver=\"GeoJSON\")\n",
    "        for network_weight in network_weight_settings:\n",
    "            for turn_penalty in turn_penalty_settings:\n",
    "                for elastic_weight in elastic_weight_settings:\n",
    "                    pairing_folder = self.output_folder + f\"{network_weight}\\\\{'with_turns' if turn_penalty else 'no_turns'}\\\\{'elastic_weight' if elastic_weight else 'unadjusted_weight'}\\\\\"\n",
    "                    self.separate_simulation_records[network_weight][turn_penalty][elastic_weight].to_csv(pairing_folder+\"betweenness_record.csv\")\n",
    "        self.log({\"event\": \"All DONE.\"})\n",
    "        self.log_df.to_csv(self.output_folder + \"time_log.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def betweenness_flow_simulation(\n",
    "        city_name=\"Somerville\",\n",
    "        data_folder=None,\n",
    "        output_folder=None,\n",
    "        pairings_file=\"Pairings.csv\",\n",
    "        network_weight_settings = [\"Perceived\", \"Geometric\"],\n",
    "        turn_penalty_settings = [False, True],\n",
    "        elastic_weight_settings = [False, True],\n",
    "        num_cores=8,\n",
    "        turn_threshold_degree=45,\n",
    "        turn_penalty_amount=30,\n",
    "        impose_crs=None\n",
    "    ):\n",
    "    '''\n",
    "    WHat used to be a major project, is now implemented into this standard workflow.....\n",
    "    '''\n",
    "    # Validate user input parameters, raise exceptions or make modifications..\n",
    "    if data_folder is None:\n",
    "        data_folder = \"Cities\\\\\"+city_name+\"\\\\Data\\\\\"\n",
    "    if output_folder is None:\n",
    "        start_time = datetime.now()\n",
    "        output_folder = f\"Cities\\\\{city_name}\\\\Simulations\\\\{start_time.year}_{start_time.month:02d}_{start_time.day:02d}_{start_time.hour:02d}_{start_time.minute:02d}\\\\\"\n",
    "\n",
    "    logger=Logger(output_folder)\n",
    "    logger.log({\"event\": \"beginning\"})\n",
    "\n",
    "    pairings = gpd.read_file(data_folder + pairings_file)\n",
    "\n",
    "    zonal = Zonal()\n",
    "    if impose_crs is not None:\n",
    "        zonal = Zonal(projected_crs=impose_crs)\n",
    "\n",
    "    zonal.load_layer(\n",
    "        layer_name='streets',\n",
    "        file_path=data_folder +  pairings.at[0, \"Network_File\"]  # \"Network.geojson\"\n",
    "    )\n",
    "    if impose_crs is not None:\n",
    "        zonal.layers[\"streets\"] = Layer(\n",
    "            label=\"streets\",\n",
    "            gdf=gpd.read_file(data_folder +  pairings.at[0, \"Network_File\"]).set_crs(impose_crs, allow_override=True),\n",
    "            show=True,\n",
    "            original_crs=impose_crs,\n",
    "            file_path=(data_folder + pairings.at[0, \"Network_File\"])\n",
    "        )\n",
    "\n",
    "    ##-------------------------------------------------------------------------------------------------------------< Data Cleaning/...\n",
    "    geometry_gdf = zonal.layers[\"streets\"].gdf\n",
    "    polygon_idxs = geometry_gdf[geometry_gdf[\"geometry\"].geom_type == \"Polygon\"].index\n",
    "    geometry_gdf.loc[polygon_idxs,\"geometry\"] = geometry_gdf.loc[polygon_idxs, \"geometry\"].exterior\n",
    "    zonal.layers[\"streets\"].gdf = geometry_gdf\n",
    "\n",
    "    if zonal.layers[\"streets\"].gdf.has_z.any():\n",
    "        def _to_2d(x, y, z):\n",
    "            return tuple(filter(None, [x, y]))\n",
    "        zonal.layers[\"streets\"].gdf[\"geometry\"] = zonal.layers[\"streets\"].gdf[\n",
    "            \"geometry\"].apply(lambda s: transform(_to_2d, s))\n",
    "\n",
    "    if (zonal.layers[\"streets\"].gdf.geometry.geom_type == \"MultiLineString\").all():\n",
    "        zonal.layers[\"streets\"].gdf[\"geometry\"] = zonal.layers[\"streets\"].gdf[\n",
    "            \"geometry\"].apply(lambda s: s.geoms[0])\n",
    "\n",
    "    print(f'streets\\t{zonal.layers[\"streets\"].gdf.crs}')\n",
    "\n",
    "    logger.simulation_start(zonal, network_weight_settings, turn_penalty_settings, elastic_weight_settings)\n",
    "\n",
    "    # Setting up a street network\n",
    "    zonal.create_street_network(\n",
    "        source_layer=\"streets\",\n",
    "        node_snapping_tolerance=1,\n",
    "        weight_attribute=None if \"Perceived\" not in network_weight_settings else pairings.at[0, \"Network_Cost\"],\n",
    "        discard_redundant_edges=True, # <---------------------------------------TODO: Expose as a parameter\n",
    "        turn_threshold_degree=turn_threshold_degree,\n",
    "        turn_penalty_amount=turn_penalty_amount\n",
    "        )\n",
    "    # This is to re-set the origins and destinations before any new iteration. TODO: implement as a Zonal function.\n",
    "    clean_node_gdf = zonal.network.nodes.copy(deep=True)\n",
    "\n",
    "    # preparing percieved and geometric weights...\n",
    "    perceived_network_weight = zonal.network.edges[\"weight\"]\n",
    "    perceived_network_weight = perceived_network_weight.apply(lambda x: max(1, x))      # To avoid any negative numbers...\n",
    "    geometric_network_weight = zonal.network.edges[\"geometry\"].length\n",
    "\n",
    "    logger.log({\"event\": \"Network topology created.\"})\n",
    "\n",
    "    for idx, pairing in pairings.iterrows():\n",
    "        # Loading layers,  if they're not already loaded.\n",
    "        if pairing[\"Origin_Name\"] not in zonal.layers:\n",
    "            zonal.load_layer(\n",
    "                layer_name=pairing[\"Origin_Name\"],\n",
    "                file_path=data_folder + pairing[\"Origin_File\"]\n",
    "            )\n",
    "            print(f\"{pairing['Origin_Name']}\\t{zonal.layers[pairing['Origin_Name']].gdf.crs}\")\n",
    "            if (impose_crs is not None) and (zonal.layers[pairing[\"Origin_Name\"]].gdf.crs != impose_crs):\n",
    "                print(\"Imposing CRS\", impose_crs)\n",
    "                # zonal.layers[pairing[\"Origin_Name\"]].gdf = gpd.read_file(data_folder + pairing[\"Origin_File\"]).set_crs(impose_crs, allow_override=True)\n",
    "                # zonal.layers[pairing[\"Origin_Name\"]].crs = impose_crs\n",
    "                zonal.layers[pairing[\"Origin_Name\"]] = Layer(\n",
    "                    label=pairing[\"Origin_Name\"],\n",
    "                    gdf=gpd.read_file(data_folder + pairing[\"Origin_File\"]).set_crs(impose_crs, allow_override=True),\n",
    "                    show=True,\n",
    "                    original_crs=impose_crs,\n",
    "                    file_path=(data_folder + pairing[\"Origin_File\"])\n",
    "                )\n",
    "\n",
    "            print(f\"{pairing['Origin_Name']}\\t{zonal.layers[pairing['Origin_Name']].gdf.crs}\\t{zonal.layers[pairing['Origin_Name']].crs}\")\n",
    "\n",
    "\n",
    "            ##-------------------------------------------------------------------------------------------------------------< Data Cleaning/...\n",
    "            if zonal.layers[pairing[\"Origin_Name\"]].gdf.has_z.any():\n",
    "                # zonal.layers[pairing[\"Origin_Name\"]].gdf[\"geometry\"] = zonal.layers[pairing[\"Origin_Name\"]].gdf[\"geometry\"].apply(\n",
    "                #     lambda s: transform(_to_2d, s))\n",
    "                zonal.layers[pairing[\"Origin_Name\"]] = Layer(\n",
    "                    label=pairing[\"Origin_Name\"],\n",
    "                    gdf=zonal.layers[pairing[\"Origin_File\"]].gdf[\"geometry\"].apply(lambda s: transform(_to_2d, s)),\n",
    "                    show=True,\n",
    "                    original_crs=impose_crs,\n",
    "                    file_path=(data_folder + pairing[\"Origin_File\"])\n",
    "                )\n",
    "\n",
    "        if pairing[\"Destination_Name\"] not in zonal.layers:\n",
    "            zonal.load_layer(\n",
    "                layer_name=pairing[\"Destination_Name\"],\n",
    "                file_path=data_folder + pairing[\"Destination_File\"]\n",
    "            )\n",
    "            if (impose_crs is not None) and (zonal.layers[pairing[\"Destination_Name\"]].gdf.crs != impose_crs):\n",
    "                # zonal.layers[pairing[\"Destination_Name\"]].gdf = gpd.read_file(data_folder + pairing[\"Destination_File\"]).set_crs(impose_crs, allow_override=True)\n",
    "                # zonal.layers[pairing[\"Destination_Name\"]].crs = impose_crs\n",
    "                zonal.layers[pairing[\"Destination_Name\"]] = Layer(\n",
    "                    label=pairing[\"Destination_Name\"],\n",
    "                    gdf=gpd.read_file(data_folder + pairing[\"Destination_File\"]).set_crs(impose_crs, allow_override=True),\n",
    "                    show=True,\n",
    "                    original_crs=impose_crs,\n",
    "                    file_path=(data_folder + pairing[\"Destination_File\"])\n",
    "                )\n",
    "            ##-------------------------------------------------------------------------------------------------------------< Data Cleaning/...\n",
    "            if zonal.layers[pairing[\"Destination_Name\"]].gdf.has_z.any():\n",
    "                # zonal.layers[pairing[\"Destination_Name\"]].gdf[\"geometry\"] = zonal.layers[pairing[\"Destination_Name\"]].gdf[\n",
    "                #     \"geometry\"].apply(lambda s: transform(_to_2d, s))\n",
    "                zonal.layers[pairing[\"Destination_Name\"]] = Layer(\n",
    "                    label=pairing[\"Destination_Name\"],\n",
    "                    gdf=zonal.layers[pairing[\"Destination_File\"]].gdf[\"geometry\"].apply(lambda s: transform(_to_2d, s)),\n",
    "                    show=True,\n",
    "                    original_crs=impose_crs,\n",
    "                    file_path=(data_folder + pairing[\"Destination_File\"])\n",
    "                )\n",
    "        \n",
    "        print(f\"{pairing['Origin_Name']}\\t{zonal.layers[pairing['Origin_Name']].gdf.crs}\")\n",
    "        print(f\"{pairing['Destination_Name']}\\t{zonal.layers[pairing['Destination_Name']].gdf.crs}\")\n",
    "        print(f\"Zonal Edge Count: {len(zonal.network.edges)}\")\n",
    "\n",
    "        # making sure to clear any existing origins and destinations before adding new ones.\n",
    "        zonal.network.nodes = clean_node_gdf.copy(deep=True)\n",
    "\n",
    "        # iterating over network weight options..\n",
    "        for network_weight in network_weight_settings:\n",
    "\n",
    "            # setting the proper network_weight\n",
    "            if network_weight == \"Perceived\":\n",
    "                zonal.network.nodes[\"weight\"] = perceived_network_weight\n",
    "            elif network_weight == \"Geometric\":\n",
    "                zonal.network.edges[\"weight\"] = geometric_network_weight\n",
    "\n",
    "            # using an effecient insert algorithm TODO: should be built inti the main Madina code... currently imported from betweenness function..\n",
    "            zonal.insert_node(\n",
    "                label=\"origin\",\n",
    "                layer_name=pairing[\"Origin_Name\"],\n",
    "                weight_attribute=pairing[\"Origin_Weight\"] if pairing[\"Origin_Weight\"] != \"Count\" else None,\n",
    "            )\n",
    "\n",
    "            zonal.insert_node(\n",
    "                label=\"destination\",\n",
    "                layer_name=pairing[\"Destination_Name\"],\n",
    "                weight_attribute=pairing[\"Destination_Weight\"] if pairing[\"Destination_Weight\"] != \"Count\" else None,\n",
    "            )\n",
    "\n",
    "            inelastic_weight = zonal.network.nodes['weight']\n",
    "\n",
    "\n",
    "            logger.log({\n",
    "                \"origin\": pairing[\"Origin_Name\"],\n",
    "                \"destination\": pairing[\"Destination_Name\"],\n",
    "                \"event\": \"Origins and Destinations prepared.\"\n",
    "                })\n",
    "\n",
    "            zonal.create_graph(light_graph=True, od_graph=True)\n",
    "\n",
    "            logger.log({\n",
    "                \"origin\": pairing[\"Origin_Name\"],\n",
    "                \"destination\": pairing[\"Destination_Name\"],\n",
    "                \"event\": \"Light and dense graphs prepared.\"\n",
    "                })\n",
    "\n",
    "            for turn_penalty in turn_penalty_settings:\n",
    "                # TODO: Investigate the value of pasing internal calculations beween simulations..\n",
    "                #retained_d_idxs = {}\n",
    "                #retained_paths = {}\n",
    "                #retained_distances = {}\n",
    "                for elastic_weight in elastic_weight_settings:\n",
    "                    # The order of these is important, as the weight is overriden by\n",
    "                    # elastic weight as there is no clean way to update weight for now.\n",
    "                    if elastic_weight:\n",
    "                        get_elastic_weight(\n",
    "                            zonal.network,\n",
    "                            search_radius=800,\n",
    "                            detour_ratio=0.002,\n",
    "                            beta=0.002,\n",
    "                            decay=True,\n",
    "                            turn_penalty=turn_penalty,\n",
    "                            retained_d_idxs=None  #<------------------- This is very sensitive to the orfer of iteration. TODO: change to a more solid implementation\n",
    "                            #retained_d_idxs=None\n",
    "                            )\n",
    "\n",
    "                        logger.log({\n",
    "                            \"origin\": pairing[\"Origin_Name\"],\n",
    "                            \"destination\": pairing[\"Destination_Name\"],\n",
    "                            \"event\": \"Elastic Weights generated.\",\n",
    "                            \"distance\": network_weight, \"tune_penalty\": turn_penalty,\n",
    "                            \"elastic_weight\": elastic_weight})\n",
    "                    else:\n",
    "                        zonal.network.nodes['weight'] = inelastic_weight\n",
    "\n",
    "\n",
    "                    node_gdf = zonal.network.nodes\n",
    "                    origin_gdf = node_gdf[node_gdf[\"type\"] == \"origin\"]\n",
    "\n",
    "                    num_cores = min(origin_gdf.shape[0], num_cores) # if not elastic_weight else 1\n",
    "\n",
    "                    betweenness_output = parallel_betweenness(\n",
    "                        zonal.network,\n",
    "                        search_radius=float(pairing[\"Radius\"]),\n",
    "                        detour_ratio=float(pairing[\"Detour\"]),\n",
    "                        decay=False if elastic_weight else True,\n",
    "                        decay_method=\"exponent\",  # \"power\", \"exponent\"\n",
    "                        beta=float(pairing[\"Beta\"]),\n",
    "                        path_detour_penalty=\"equal\",  # \"power\", \"exponent\", \"equal\"\n",
    "                        origin_weights=True,\n",
    "                        closest_destination=False,\n",
    "                        destination_weights=True,  # if pairing[\"Destination_Name\"] != \"Mosques\" else False,\n",
    "                        # perceived_distance=False,\n",
    "                        num_cores=num_cores,\n",
    "                        light_graph=True,\n",
    "                        turn_penalty=turn_penalty,\n",
    "                        #retained_d_idxs=retained_d_idxs if elastic_weight else None,\n",
    "                        #retained_paths=retained_paths if elastic_weight else None,\n",
    "                        #retained_distances=retained_distances if elastic_weight else None,\n",
    "                        rertain_expensive_data=False if elastic_weight else True,\n",
    "                        retained_d_idxs=None,\n",
    "                        retained_paths=None,\n",
    "                        retained_distances=None,\n",
    "                        #rertain_expensive_data=False\n",
    "                    )\n",
    "\n",
    "                    if not elastic_weight: #< -------------------------------------------------------- sensitive to order of looping #TODO: implement for more general case.\n",
    "                        retained_d_idxs = betweenness_output[\"retained_d_idxs\"]\n",
    "                        #retained_paths = betweenness_output[\"retained_paths\"]\n",
    "                        #retained_distances = betweenness_output[\"retained_distances\"]\n",
    "\n",
    "                    logger.log({\n",
    "                        \"origin\": pairing[\"Origin_Name\"],\n",
    "                        \"destination\": pairing[\"Destination_Name\"],\n",
    "                        \"event\": \"Betweenness estimated.\",\n",
    "                        \"distance\": network_weight,\n",
    "                        \"tune_penalty\": turn_penalty,\n",
    "                        \"elastic_weight\": elastic_weight})\n",
    "                    logger.pairing_end(zonal, pairing, network_weight, turn_penalty, elastic_weight)\n",
    "                    \n",
    "    logger.simulation_end(network_weight_settings, turn_penalty_settings, elastic_weight_settings)\n",
    "    Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "    zonal.network.edges.to_csv(output_folder + \"edge_gdf.csv\")\n",
    "    zonal.network.nodes.to_csv(output_folder + \"node_gdf.csv\")\n",
    "\n",
    "    # zonal.network.nodes.drop(columns=['nearest_street_node_distance']).to_csv(output_folder + \"node_gdf_part_1.csv\")\n",
    "    # zonal.network.nodes['nearest_street_node_distance'].to_csv(output_folder + \"node_gdf_part_2_dict.csv\")\n",
    "    # nearest_street_node = pd.DataFrame({\n",
    "    #     'left_id': [dict(dict(d).get('left')).get('node_id') for d in zonal.network.nodes['nearest_street_node_distance'] if d is not nan],\n",
    "    #     'left_weight': [dict(dict(d).get('left')).get('weight') for d in zonal.network.nodes['nearest_street_node_distance']],\n",
    "    #     'right_id': [dict(dict(d).get('right')).get('node_id') for d in zonal.network.nodes['nearest_street_node_distance']],\n",
    "    #     'right_weight': [dict(dict(d).get('right')).get('weight') for d in zonal.network.nodes['nearest_street_node_distance']]\n",
    "    # })\n",
    "    # nearest_street_node.to_csv(output_folder + \"node_gdf_part_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time\tseconds elapsed\tdiatance method\telastic_weight\t    origin     \t  destination  \tevent\n",
      "0.0000\t\t0\t\t\t\t---\t\t---\t\t---\t\t      ---      \t      ---      \tbeginning\n",
      "streets\tepsg:26986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\56830\\OneDrive - Massachusetts Institute of Technology\\UROPs\\UNA\\madina\\test_ipynb\\..\\madina\\zonal\\network_utils.py:171: FutureWarning: The `query_bulk()` method is deprecated and will be removed in GeoPandas 1.0. You can use the `query()` method instead.\n",
      "  matching = point_geometries.sindex.query_bulk(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "[  19   20   37   42   43   70   83   84  109  368  373  387  392  479\n",
      "  484  485  774  779  837  849  852  875  892 1049 1202 1261 1262 1315\n",
      " 1354 1355 1417 1429 1430 1461 1462 1486 1497 1498 1512 1584 1643 1655\n",
      " 1689 1707 1728 1769 1785 1803 1854 1887 1888 1905 1932 1980 1994 2001\n",
      " 2031 2046 2047 2118 2119 2273 2317 2410 2411 2422 2424 2526 2527 2561\n",
      " 2562 2694 2695 2696 2717 2826 2828 2829 2889 2916 2930 3088 3089 3119\n",
      " 3126 3127 3164 3165 3206 3207 3228 3249 3250 3344 3345 3874 3875 4037\n",
      " 4038 4531 4532 4584 4586 4753 4799 4804 4805 5152 5153 5199 5218 5246\n",
      " 5247 5248 5249 5267 5276 5379 5540 5548 5549 5665 5666 5712 5833 5841\n",
      " 5842 5883 5899 5912 5991 6001 6017 6019 6233 6255 6262 6296 6298 6299\n",
      " 6311 7013 7060 7061 7070 7073 7096 7097 7104 7154 7155 7168 7199 7200\n",
      " 7230 7259 7260 7307 7375 7467 7498 7515 7716 8224 8297 8449 8834 8880\n",
      " 8881 8884 8885 8911 8916 9103 9246 9287 9385 9557 9589]\n",
      "80 179\n",
      "{2561, 3088, 19, 7199, 8224, 5666, 37, 42, 3126, 7230, 2118, 9287, 83, 6233, 7259, 3164, 109, 6255, 6262, 5247, 5249, 3206, 2696, 6296, 6298, 6299, 3228, 2717, 5276, 6311, 9385, 8881, 1202, 3250, 8884, 4799, 4804, 5841, 1261, 8449, 1803, 2317, 3345, 5912, 3874, 2889, 7498, 1354, 849, 1888, 2916, 7013, 2410, 875, 1905, 2930, 373, 2422, 892, 6019, 392, 1417, 1932, 9103, 1429, 7070, 7073, 5549, 4531, 7096, 7104, 4037, 2001, 1498, 2526, 485, 1512, 4586, 7154, 2046}\n",
      "10221 10122\n",
      "21.0000\t\t21\t\t\t\t---\t\t---\t\t---\t\t      ---      \t      ---      \tNetwork topology created.\n",
      "Bus\tEPSG:26986\n",
      "Bus\tEPSG:26986\tEPSG:26986\n",
      "Bus\tEPSG:26986\n",
      "Subway\tEPSG:26986\n",
      "Zonal Edge Count: 10122\n",
      "21.0000\t\t0\t\t\t\t---\t\t---\t\t---\t\t      Bus      \t    Subway     \tOrigins and Destinations prepared.\n",
      "22.0000\t\t1\t\t\t\t---\t\t---\t\t---\t\t      Bus      \t    Subway     \tLight and dense graphs prepared.\n",
      "-------------------------------------------\n",
      "All cores done in 6.93\n",
      "-------------------------------------------\n",
      "29.0000\t\t7\t\t\t\tGeometric\t\tTrue\t\tFalse\t\t      Bus      \t    Subway     \tBetweenness estimated.\n",
      "30.0000\t\t1\t\t\t\tGeometric\t\tTrue\t\tFalse\t\t      Bus      \t    Subway     \tOutput saved\n",
      "Home\tEPSG:26986\n",
      "Home\tEPSG:26986\tEPSG:26986\n",
      "Home\tEPSG:26986\n",
      "Subway\tEPSG:26986\n",
      "Zonal Edge Count: 10122\n",
      "32.0000\t\t2\t\t\t\t---\t\t---\t\t---\t\t     Home      \t    Subway     \tOrigins and Destinations prepared.\n",
      "48.0000\t\t16\t\t\t\t---\t\t---\t\t---\t\t     Home      \t    Subway     \tLight and dense graphs prepared.\n",
      "-------------------------------------------\n",
      "All cores done in 262.97\n",
      "-------------------------------------------\n",
      "311.0000\t\t263\t\t\t\tGeometric\t\tTrue\t\tFalse\t\t     Home      \t    Subway     \tBetweenness estimated.\n",
      "312.0000\t\t1\t\t\t\tGeometric\t\tTrue\t\tFalse\t\t     Home      \t    Subway     \tOutput saved\n",
      "312.0000\t\t0\t\t\t\t---\t\t---\t\t---\t\t      ---      \t      ---      \tAll DONE.\n"
     ]
    }
   ],
   "source": [
    "betweenness_flow_simulation(\n",
    "    city_name=\"Somerville\",\n",
    "    data_folder=f'Cities\\\\Somerville\\\\Data\\\\',\n",
    "    pairings_file=\"Pairings.csv\",\n",
    "    network_weight_settings=[\"Geometric\"],          # [\"Perceived\", \"Geometric\"],\n",
    "    turn_penalty_settings=[True],                   # [False, True]\n",
    "    elastic_weight_settings=[False],          # [False, True]\n",
    "    num_cores=20,\n",
    "    turn_threshold_degree=45,\n",
    "    turn_penalty_amount=62.3,\n",
    "    impose_crs='epsg:26986'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
