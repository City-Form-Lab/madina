{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Expanding Madina\n",
    "## Goals\n",
    "* Implementing a betweenness flow sumulation function that just can be called from a zonal object with minimal parameters\n",
    "* implementing a dunction that takews count data and outputs a list of statistical models and thwir interporetation\n",
    "* set up a complete docstring template that's compliant and complete..\n",
    "* use code to run sommerville, run stats and interpret\n",
    "* publish the docstring on cityformlab.mit.edu or on github.com\n",
    "* use code to runn Beirut, interpret results\n",
    "* use mofel to run Melbourn, NYC,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from shapely.ops import transform\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from madina.zonal.zonal import Layer\n",
    "from madina.zonal.zonal import Zonal\n",
    "from madina.una.betweenness import parallel_betweenness\n",
    "from madina.una.elastic import get_elastic_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger():\n",
    "    def __init__(self, output_folder):\n",
    "        self.output_folder = output_folder\n",
    "        self.start_time = datetime.now()\n",
    "        self.log_df = pd.DataFrame(\n",
    "            {\n",
    "                \"time\": pd.Series(dtype='datetime64[ns]'),\n",
    "                \"distance\": pd.Series(dtype=\"string\"),\n",
    "                \"tune_penalty\": pd.Series(dtype=\"string\"),\n",
    "                \"elastic_weight\": pd.Series(dtype=\"string\"),\n",
    "                \"origin\": pd.Series(dtype=\"string\"),\n",
    "                \"destination\": pd.Series(dtype=\"string\"),\n",
    "                \"event\": pd.Series(dtype=\"string\")\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def simulation_start(self, zone, network_weight_settings, turn_penalty_settings, elastic_weight_settings):\n",
    "        ##-------------------------------------------------------------------------------------------------------------< Betweenness Recode...\n",
    "        self.betweenness_record = zone.layers['streets'].gdf.copy(deep=True)\n",
    "        self.separate_simulation_records = {}\n",
    "        for network_weight in network_weight_settings:\n",
    "            self.separate_simulation_records[network_weight] = {}\n",
    "            for turn_penalty in turn_penalty_settings:\n",
    "                self.separate_simulation_records[network_weight][turn_penalty] = {}\n",
    "                for elastic_weight in elastic_weight_settings:\n",
    "                    self.separate_simulation_records[network_weight][turn_penalty][elastic_weight] = self.betweenness_record.copy(deep=True)\n",
    "\n",
    "    def log(self, input_dict):\n",
    "        input_dict[\"time\"] = datetime.now()\n",
    "        if self.log_df.shape[0] == 0:\n",
    "            print(f\"total time\\tseconds elapsed\\tdiatance method\\telastic_weight\\t{'origin':^15s}\\t{'destination':^15s}\\tevent\")\n",
    "            input_dict[\"seconds_elapsed\"] = 0\n",
    "            input_dict[\"cumulative_seconds\"] = 0\n",
    "        else:\n",
    "            time_elapsed = (input_dict[\"time\"] - self.log_df.iloc[-1][\"time\"]).seconds\n",
    "            input_dict[\"seconds_elapsed\"] = time_elapsed\n",
    "            input_dict[\"cumulative_seconds\"] = self.log_df[\"seconds_elapsed\"].sum() + time_elapsed\n",
    "\n",
    "        for column_name in self.log_df.columns:\n",
    "            if column_name not in input_dict:\n",
    "                input_dict[column_name] = \"---\"\n",
    "\n",
    "        self.log_df = pd.concat([self.log_df, pd.DataFrame([input_dict])], ignore_index=True)\n",
    "        print(\n",
    "            f\"{input_dict['cumulative_seconds']:6.4f}\\t\\t\"\n",
    "            f\"{input_dict['seconds_elapsed']}\\t\\t\\t\\t\"\n",
    "            f\"{input_dict['distance']}\\t\\t\"\n",
    "            f\"{input_dict['tune_penalty']}\\t\\t\"\n",
    "            f\"{input_dict['elastic_weight']}\\t\\t\"\n",
    "            f\"{input_dict['origin']:^15s}\\t\"\n",
    "            f\"{input_dict['destination']:^15s}\\t\"\n",
    "            f\"{input_dict['event']}\"\n",
    "        )\n",
    "\n",
    "    def simulation_end(self, network_weight_settings, turn_penalty_settings, elastic_weight_settings):\n",
    "        self.betweenness_record.to_csv(self.output_folder + \"betweenness_record.csv\")\n",
    "        #self.betweenness_record.to_file(self.output_folder + \"street_network_betweenness_record.geojson\", driver=\"GeoJSON\")\n",
    "        for network_weight in network_weight_settings:\n",
    "            for turn_penalty in turn_penalty_settings:\n",
    "                for elastic_weight in elastic_weight_settings:\n",
    "                    pairing_folder = self.output_folder + f\"{network_weight}\\\\{'with_turns' if turn_penalty else 'no_turns'}\\\\{'elastic_weight' if elastic_weight else 'unadjusted_weight'}\\\\\"\n",
    "                    self.separate_simulation_records[network_weight][turn_penalty][elastic_weight].to_csv(pairing_folder+\"betweenness_record.csv\")\n",
    "        self.log({\"event\": \"All DONE.\"})\n",
    "        self.log_df.to_csv(self.output_folder + \"time_log.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def betweenness_flow_simulation(\n",
    "        city_name=\"Somerville\",\n",
    "        data_folder=None,\n",
    "        output_folder=None,\n",
    "        pairings_file=\"Pairings.csv\",\n",
    "        network_weight_settings = [\"Perceived\", \"Geometric\"],\n",
    "        turn_penalty_settings = [False, True],\n",
    "        elastic_weight_settings = [False, True],\n",
    "        num_cores=8,\n",
    "        turn_threshold_degree=45,\n",
    "        turn_penalty_amount=30,\n",
    "        impose_crs=None\n",
    "    ):\n",
    "    '''\n",
    "    WHat used to be a major project, is now implemented into this standard workflow.....\n",
    "    '''\n",
    "    # Validate user input parameters, raise exceptions or make modifications..\n",
    "    if data_folder is None:\n",
    "        data_folder = \"Cities\\\\\"+city_name+\"\\\\Data\\\\\"\n",
    "    if output_folder is None:\n",
    "        start_time = datetime.now()\n",
    "        output_folder = f\"Cities\\\\{city_name}\\\\Simulations\\\\{start_time.year}_{start_time.month:02d}_{start_time.day:02d}_{start_time.hour:02d}_{start_time.minute:02d}\\\\ \"\n",
    "\n",
    "    logger=Logger(output_folder)\n",
    "    logger.log({\"event\": \"beginning\"})\n",
    "\n",
    "    pairings = gpd.read_file(data_folder + pairings_file)\n",
    "\n",
    "    zonal = Zonal()\n",
    "    if impose_crs is not None:\n",
    "        zonal = Zonal(projected_crs=impose_crs)\n",
    "\n",
    "    zonal.load_layer(\n",
    "        layer_name='streets',\n",
    "        file_path=data_folder +  pairings.at[0, \"Network_File\"]  # \"Network.geojson\"\n",
    "    )\n",
    "    if impose_crs is not None:\n",
    "        zonal.layers[\"streets\"] = Layer(\n",
    "            label=\"streets\",\n",
    "            gdf=gpd.read_file(data_folder +  pairings.at[0, \"Network_File\"]).set_crs(impose_crs, allow_override=True),\n",
    "            show=True,\n",
    "            original_crs=impose_crs,\n",
    "            file_path=(data_folder + pairings.at[0, \"Network_File\"])\n",
    "        )\n",
    "\n",
    "    print(f'streets\\t{zonal.layers[\"streets\"].gdf.crs}')\n",
    "\n",
    "    logger.simulation_start(zonal, network_weight_settings, turn_penalty_settings, elastic_weight_settings)\n",
    "\n",
    "    ##-------------------------------------------------------------------------------------------------------------< Data Cleaning/...\n",
    "    geometry_gdf = zonal.layers[\"streets\"].gdf\n",
    "    polygon_idxs = geometry_gdf[geometry_gdf[\"geometry\"].geom_type == \"Polygon\"].index\n",
    "    geometry_gdf.loc[polygon_idxs,\"geometry\"] = geometry_gdf.loc[polygon_idxs, \"geometry\"].exterior\n",
    "    zonal.layers[\"streets\"].gdf = geometry_gdf\n",
    "\n",
    "    if zonal.layers[\"streets\"].gdf.has_z.any():\n",
    "        def _to_2d(x, y, z):\n",
    "            return tuple(filter(None, [x, y]))\n",
    "        zonal.layers[\"streets\"].gdf[\"geometry\"] = zonal.layers[\"streets\"].gdf[\n",
    "            \"geometry\"].apply(lambda s: transform(_to_2d, s))\n",
    "\n",
    "    if (zonal.layers[\"streets\"].gdf.geometry.geom_type == \"MultiLineString\").all():\n",
    "        zonal.layers[\"streets\"].gdf[\"geometry\"] = zonal.layers[\"streets\"].gdf[\n",
    "            \"geometry\"].apply(lambda s: s.geoms[0])\n",
    "\n",
    "    # Setting up a street network\n",
    "    zonal.create_street_network(\n",
    "        source_layer=\"streets\",\n",
    "        node_snapping_tolerance=1,\n",
    "        weight_attribute=None if \"Perceived\" not in network_weight_settings else pairings.at[0, \"Network_Cost\"],\n",
    "        discard_redundant_edges=True # <---------------------------------------TODO: Expose as a parameter\n",
    "        )\n",
    "    # This is to re-set the origins and destinations before any new iteration. TODO: implement as a Zonal function.\n",
    "    clean_node_gdf = zonal.network.nodes.copy(deep=True)\n",
    "\n",
    "    # preparing percieved and geometric weights...\n",
    "    perceived_network_weight = zonal.network.edges[\"weight\"]\n",
    "    perceived_network_weight = perceived_network_weight.apply(lambda x: max(1, x))      # To avoid any negative numbers...\n",
    "    geometric_network_weight = zonal.network.edges[\"geometry\"].length\n",
    "\n",
    "    logger.log({\"event\": \"Network topology created.\"})\n",
    "\n",
    "\n",
    "    for idx, pairing in pairings.iterrows():\n",
    "        # Loading layers,  if they're not already loaded.\n",
    "        if pairing[\"Origin_Name\"] not in zonal.layers:\n",
    "            zonal.load_layer(\n",
    "                layer_name=pairing[\"Origin_Name\"],\n",
    "                file_path=data_folder + pairing[\"Origin_File\"]\n",
    "            )\n",
    "            if (impose_crs is not None) and (zonal.layers[pairing[\"Origin_Name\"]].crs != impose_crs):\n",
    "                zonal.layers[pairing[\"Origin_Name\"]].gdf = gpd.read_file(data_folder + pairing[\"Origin_File\"]).set_crs(impose_crs, allow_override=True)\n",
    "                zonal.layers[pairing[\"Origin_Name\"]].crs = impose_crs\n",
    "\n",
    "\n",
    "            ##-------------------------------------------------------------------------------------------------------------< Data Cleaning/...\n",
    "            if zonal.layers[pairing[\"Origin_Name\"]].gdf.has_z.any():\n",
    "                zonal.layers[pairing[\"Origin_Name\"]].gdf[\"geometry\"] = zonal.layers[pairing[\"Origin_Name\"]].gdf[\"geometry\"].apply(\n",
    "                    lambda s: transform(_to_2d, s))\n",
    "        if pairing[\"Destination_Name\"] not in zonal.layers:\n",
    "            zonal.load_layer(\n",
    "                layer_name=pairing[\"Destination_Name\"],\n",
    "                file_path=data_folder + pairing[\"Destination_File\"]\n",
    "            )\n",
    "            if (impose_crs is not None) and (zonal.layers[pairing[\"Destination_Name\"]].crs != impose_crs):\n",
    "                zonal.layers[pairing[\"Destination_Name\"]].gdf = gpd.read_file(data_folder + pairing[\"Destination_File\"]).set_crs(impose_crs, allow_override=True)\n",
    "                zonal.layers[pairing[\"Destination_Name\"]].crs = impose_crs\n",
    "            ##-------------------------------------------------------------------------------------------------------------< Data Cleaning/...\n",
    "            if zonal.layers[pairing[\"Destination_Name\"]].gdf.has_z.any():\n",
    "                zonal.layers[pairing[\"Destination_Name\"]].gdf[\"geometry\"] = zonal.layers[pairing[\"Destination_Name\"]].gdf[\n",
    "                    \"geometry\"].apply(lambda s: transform(_to_2d, s))\n",
    "        print(f\"{pairing['Origin_Name']}\\t{zonal.layers[pairing['Origin_Name']].gdf.crs}\")\n",
    "        print(f\"{pairing['Destination_Name']}\\t{zonal.layers[pairing['Destination_Name']].gdf.crs}\")\n",
    "\n",
    "        # making sure to clear any existing origins and destinations before adding new ones.\n",
    "        zonal.network.nodes = clean_node_gdf.copy(deep=True)\n",
    "\n",
    "        # iterating over network weight options..\n",
    "        for network_weight in network_weight_settings:\n",
    "\n",
    "            # setting the proper network_weight\n",
    "            if network_weight == \"Perceived\":\n",
    "                zonal.network.nodes[\"weight\"] = perceived_network_weight\n",
    "            elif network_weight == \"Geometric\":\n",
    "                zonal.network.edges[\"weight\"] = geometric_network_weight\n",
    "\n",
    "            # using an effecient insert algorithm TODO: should be built inti the main Madina code... currently imported from betweenness function..\n",
    "            zonal.insert_node(\n",
    "                label=\"origin\",\n",
    "                layer_name=pairing[\"Origin_Name\"],\n",
    "                weight_attribute=pairing[\"Origin_Weight\"] if pairing[\"Origin_Weight\"] != \"Count\" else None,\n",
    "            )\n",
    "\n",
    "            zonal.insert_node(\n",
    "                label=\"destination\",\n",
    "                layer_name=pairing[\"Destination_Name\"],\n",
    "                weight_attribute=pairing[\"Destination_Weight\"] if pairing[\"Destination_Weight\"] != \"Count\" else None,\n",
    "            )\n",
    "\n",
    "            inelastic_weight = zonal.network.nodes['weight']\n",
    "\n",
    "\n",
    "            logger.log({\n",
    "                \"origin\": pairing[\"Origin_Name\"],\n",
    "                \"destination\": pairing[\"Destination_Name\"],\n",
    "                \"event\": \"Origins and Destinations prepared.\"\n",
    "                })\n",
    "\n",
    "            zonal.create_graph(light_graph=True, od_graph=True)\n",
    "\n",
    "            logger.log({\n",
    "                \"origin\": pairing[\"Origin_Name\"],\n",
    "                \"destination\": pairing[\"Destination_Name\"],\n",
    "                \"event\": \"Light and dense graphs prepared.\"\n",
    "                })\n",
    "\n",
    "            for turn_penalty in turn_penalty_settings:\n",
    "                # TODO: Investigate the value of pasing internal calculations beween simulations..\n",
    "                #retained_d_idxs = {}\n",
    "                #retained_paths = {}\n",
    "                #retained_distances = {}\n",
    "                for elastic_weight in elastic_weight_settings:\n",
    "                    # The order of these is important, as the weight is overriden by\n",
    "                    # elastic weight as there is no clean way to update weight for now.\n",
    "                    if elastic_weight:\n",
    "                        get_elastic_weight(\n",
    "                            zonal.network,\n",
    "                            search_radius=800,\n",
    "                            detour_ratio=0.002,\n",
    "                            beta=0.002,\n",
    "                            decay=True,\n",
    "                            turn_penalty=turn_penalty,\n",
    "                            retained_d_idxs=None  #<------------------- This is very sensitive to the orfer of iteration. TODO: change to a more solid implementation\n",
    "                            #retained_d_idxs=None\n",
    "                            )\n",
    "\n",
    "                        logger.log({\n",
    "                            \"origin\": pairing[\"Origin_Name\"],\n",
    "                            \"destination\": pairing[\"Destination_Name\"],\n",
    "                            \"event\": \"Elastic Weights generated.\",\n",
    "                            \"distance\": network_weight, \"tune_penalty\": turn_penalty,\n",
    "                            \"elastic_weight\": elastic_weight})\n",
    "                    else:\n",
    "                        zonal.network.nodes['weight'] = inelastic_weight\n",
    "\n",
    "\n",
    "                    node_gdf = zonal.network.nodes\n",
    "                    origin_gdf = node_gdf[node_gdf[\"type\"] == \"origin\"]\n",
    "\n",
    "                    num_cores = min(origin_gdf.shape[0], num_cores) # if not elastic_weight else 1\n",
    "\n",
    "                    betweenness_output = parallel_betweenness(\n",
    "                        zonal.network,\n",
    "                        search_radius=float(pairing[\"Radius\"]),\n",
    "                        detour_ratio=float(pairing[\"Detour\"]),\n",
    "                        decay=False if elastic_weight else True,\n",
    "                        decay_method=\"exponent\",  # \"power\", \"exponent\"\n",
    "                        beta=float(pairing[\"Beta\"]),\n",
    "                        path_detour_penalty=\"equal\",  # \"power\", \"exponent\", \"equal\"\n",
    "                        origin_weights=True,\n",
    "                        closest_destination=False,\n",
    "                        destination_weights=True,  # if pairing[\"Destination_Name\"] != \"Mosques\" else False,\n",
    "                        # perceived_distance=False,\n",
    "                        num_cores=num_cores,\n",
    "                        light_graph=True,\n",
    "                        turn_penalty=turn_penalty,\n",
    "                        #retained_d_idxs=retained_d_idxs if elastic_weight else None,\n",
    "                        #retained_paths=retained_paths if elastic_weight else None,\n",
    "                        #retained_distances=retained_distances if elastic_weight else None,\n",
    "                        rertain_expensive_data=False if elastic_weight else True,\n",
    "                        retained_d_idxs=None,\n",
    "                        retained_paths=None,\n",
    "                        retained_distances=None,\n",
    "                        #rertain_expensive_data=False\n",
    "                    )\n",
    "\n",
    "                    if not elastic_weight: #< -------------------------------------------------------- sensitive to order of looping #TODO: implement for more general case.\n",
    "                        retained_d_idxs = betweenness_output[\"retained_d_idxs\"]\n",
    "                        #retained_paths = betweenness_output[\"retained_paths\"]\n",
    "                        #retained_distances = betweenness_output[\"retained_distances\"]\n",
    "\n",
    "                    logger.log({\n",
    "                        \"origin\": pairing[\"Origin_Name\"],\n",
    "                        \"destination\": pairing[\"Destination_Name\"],\n",
    "                        \"event\": \"Betweenness estimated.\",\n",
    "                        \"distance\": network_weight,\n",
    "                        \"tune_penalty\": turn_penalty,\n",
    "                        \"elastic_weight\": elastic_weight})\n",
    "                    \n",
    "    logger.simulation_end(network_weight_settings, turn_penalty_settings, elastic_weight_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time\tseconds elapsed\tdiatance method\telastic_weight\t    origin     \t  destination  \tevent\n",
      "0.0000\t\t0\t\t\t\t---\t\t---\t\t---\t\t      ---      \t      ---      \tbeginning\n",
      "\n",
      "Position 1 ----- streets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\una\\lib\\site-packages\\geopandas\\array.py:917: RuntimeWarning: All-NaN slice encountered\n",
      "  np.nanmin(b[:, 0]),  # minx\n",
      "c:\\ProgramData\\Anaconda3\\envs\\una\\lib\\site-packages\\geopandas\\array.py:918: RuntimeWarning: All-NaN slice encountered\n",
      "  np.nanmin(b[:, 1]),  # miny\n",
      "c:\\ProgramData\\Anaconda3\\envs\\una\\lib\\site-packages\\geopandas\\array.py:919: RuntimeWarning: All-NaN slice encountered\n",
      "  np.nanmax(b[:, 2]),  # maxx\n",
      "c:\\ProgramData\\Anaconda3\\envs\\una\\lib\\site-packages\\geopandas\\array.py:920: RuntimeWarning: All-NaN slice encountered\n",
      "  np.nanmax(b[:, 3]),  # maxy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "streets\tepsg:26986\n",
      "counter = 100, progress =  0.98\n",
      "counter = 200, progress =  1.96\n",
      "counter = 300, progress =  2.94\n",
      "counter = 400, progress =  3.91\n",
      "counter = 500, progress =  4.89\n",
      "counter = 600, progress =  5.87\n",
      "counter = 700, progress =  6.85\n",
      "counter = 800, progress =  7.83\n",
      "counter = 900, progress =  8.81\n",
      "counter = 1000, progress =  9.78\n",
      "counter = 1100, progress = 10.76\n",
      "counter = 1200, progress = 11.74\n",
      "counter = 1300, progress = 12.72\n",
      "counter = 1400, progress = 13.70\n",
      "counter = 1500, progress = 14.68\n",
      "counter = 1600, progress = 15.65\n",
      "counter = 1700, progress = 16.63\n",
      "counter = 1800, progress = 17.61\n",
      "counter = 1900, progress = 18.59\n",
      "counter = 2000, progress = 19.57\n",
      "counter = 2100, progress = 20.55\n",
      "counter = 2200, progress = 21.52\n",
      "counter = 2300, progress = 22.50\n",
      "counter = 2400, progress = 23.48\n",
      "counter = 2500, progress = 24.46\n",
      "counter = 2600, progress = 25.44\n",
      "counter = 2700, progress = 26.42\n",
      "counter = 2800, progress = 27.39\n",
      "counter = 2900, progress = 28.37\n",
      "counter = 3000, progress = 29.35\n",
      "counter = 3100, progress = 30.33\n",
      "counter = 3200, progress = 31.31\n",
      "counter = 3300, progress = 32.29\n",
      "counter = 3400, progress = 33.26\n",
      "counter = 3500, progress = 34.24\n",
      "counter = 3600, progress = 35.22\n",
      "counter = 3700, progress = 36.20\n",
      "counter = 3800, progress = 37.18\n",
      "counter = 3900, progress = 38.16\n",
      "counter = 4000, progress = 39.14\n",
      "counter = 4100, progress = 40.11\n",
      "counter = 4200, progress = 41.09\n",
      "counter = 4300, progress = 42.07\n",
      "counter = 4400, progress = 43.05\n",
      "counter = 4500, progress = 44.03\n",
      "counter = 4600, progress = 45.01\n",
      "counter = 4700, progress = 45.98\n",
      "counter = 4800, progress = 46.96\n",
      "counter = 4900, progress = 47.94\n",
      "counter = 5000, progress = 48.92\n",
      "counter = 5100, progress = 49.90\n",
      "counter = 5200, progress = 50.88\n",
      "counter = 5300, progress = 51.85\n",
      "counter = 5400, progress = 52.83\n",
      "counter = 5500, progress = 53.81\n",
      "counter = 5600, progress = 54.79\n",
      "counter = 5700, progress = 55.77\n",
      "counter = 5800, progress = 56.75\n",
      "counter = 5900, progress = 57.72\n",
      "counter = 6000, progress = 58.70\n",
      "counter = 6100, progress = 59.68\n",
      "counter = 6200, progress = 60.66\n",
      "counter = 6300, progress = 61.64\n",
      "counter = 6400, progress = 62.62\n",
      "counter = 6500, progress = 63.59\n",
      "counter = 6600, progress = 64.57\n",
      "counter = 6700, progress = 65.55\n",
      "counter = 6800, progress = 66.53\n",
      "counter = 6900, progress = 67.51\n",
      "counter = 7000, progress = 68.49\n",
      "counter = 7100, progress = 69.46\n",
      "counter = 7200, progress = 70.44\n",
      "counter = 7300, progress = 71.42\n",
      "counter = 7400, progress = 72.40\n",
      "counter = 7500, progress = 73.38\n",
      "counter = 7600, progress = 74.36\n",
      "counter = 7700, progress = 75.34\n",
      "counter = 7800, progress = 76.31\n",
      "counter = 7900, progress = 77.29\n",
      "counter = 8000, progress = 78.27\n",
      "counter = 8100, progress = 79.25\n",
      "counter = 8200, progress = 80.23\n",
      "counter = 8300, progress = 81.21\n",
      "counter = 8400, progress = 82.18\n",
      "counter = 8500, progress = 83.16\n",
      "counter = 8600, progress = 84.14\n",
      "counter = 8700, progress = 85.12\n",
      "counter = 8800, progress = 86.10\n",
      "counter = 8900, progress = 87.08\n",
      "counter = 9000, progress = 88.05\n",
      "counter = 9100, progress = 89.03\n",
      "counter = 9200, progress = 90.01\n",
      "counter = 9300, progress = 90.99\n",
      "counter = 9400, progress = 91.97\n",
      "counter = 9500, progress = 92.95\n",
      "counter = 9600, progress = 93.92\n",
      "counter = 9700, progress = 94.90\n",
      "counter = 9800, progress = 95.88\n",
      "counter = 9900, progress = 96.86\n",
      "counter = 10000, progress = 97.84\n",
      "counter = 10100, progress = 98.82\n",
      "counter = 10200, progress = 99.79\n",
      "redundant edge report: zero_length_edges = 15, redundant_edges = 80\n",
      "185.0000\t\t185\t\t\t\t---\t\t---\t\t---\t\t      ---      \t      ---      \tNetwork topology created.\n",
      "\n",
      "Position 2 ----- Home\n",
      "Position 1 ----- streets\n",
      "\n",
      "Position 3 ----- Subway\n",
      "Position 2 ----- Home\n",
      "Position 1 ----- streets\n",
      "Home\tEPSG:4326\n",
      "Subway\tEPSG:4326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\una\\lib\\site-packages\\geopandas\\array.py:917: RuntimeWarning: All-NaN slice encountered\n",
      "  np.nanmin(b[:, 0]),  # minx\n",
      "c:\\ProgramData\\Anaconda3\\envs\\una\\lib\\site-packages\\geopandas\\array.py:918: RuntimeWarning: All-NaN slice encountered\n",
      "  np.nanmin(b[:, 1]),  # miny\n",
      "c:\\ProgramData\\Anaconda3\\envs\\una\\lib\\site-packages\\geopandas\\array.py:919: RuntimeWarning: All-NaN slice encountered\n",
      "  np.nanmax(b[:, 2]),  # maxx\n",
      "c:\\ProgramData\\Anaconda3\\envs\\una\\lib\\site-packages\\geopandas\\array.py:920: RuntimeWarning: All-NaN slice encountered\n",
      "  np.nanmax(b[:, 3]),  # maxy\n",
      "c:\\ProgramData\\Anaconda3\\envs\\una\\lib\\site-packages\\geopandas\\array.py:917: RuntimeWarning: All-NaN slice encountered\n",
      "  np.nanmin(b[:, 0]),  # minx\n",
      "c:\\ProgramData\\Anaconda3\\envs\\una\\lib\\site-packages\\geopandas\\array.py:918: RuntimeWarning: All-NaN slice encountered\n",
      "  np.nanmin(b[:, 1]),  # miny\n",
      "c:\\ProgramData\\Anaconda3\\envs\\una\\lib\\site-packages\\geopandas\\array.py:919: RuntimeWarning: All-NaN slice encountered\n",
      "  np.nanmax(b[:, 2]),  # maxx\n",
      "c:\\ProgramData\\Anaconda3\\envs\\una\\lib\\site-packages\\geopandas\\array.py:920: RuntimeWarning: All-NaN slice encountered\n",
      "  np.nanmax(b[:, 3]),  # maxy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188.0000\t\t3\t\t\t\t---\t\t---\t\t---\t\t     Home      \t    Subway     \tOrigins and Destinations prepared.\n",
      "188.0000\t\t0\t\t\t\t---\t\t---\t\t---\t\t     Home      \t    Subway     \tLight and dense graphs prepared.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m betweenness_flow_simulation(\n\u001b[0;32m      2\u001b[0m     city_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mSomerville\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      3\u001b[0m     data_folder\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mCities\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mSomerville\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mData\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      4\u001b[0m     output_folder\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mCities\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mSomerville\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mSimulations\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      5\u001b[0m     pairings_file\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPairings.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      6\u001b[0m     network_weight_settings\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mGeometric\u001b[39;49m\u001b[39m\"\u001b[39;49m],          \u001b[39m# [\"Perceived\", \"Geometric\"],\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m     turn_penalty_settings\u001b[39m=\u001b[39;49m[\u001b[39mTrue\u001b[39;49;00m],                   \u001b[39m# [False, True]\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m     elastic_weight_settings\u001b[39m=\u001b[39;49m[\u001b[39mTrue\u001b[39;49;00m],          \u001b[39m# [False, True]\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m     num_cores\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,\n\u001b[0;32m     10\u001b[0m     turn_threshold_degree\u001b[39m=\u001b[39;49m\u001b[39m45\u001b[39;49m,\n\u001b[0;32m     11\u001b[0m     turn_penalty_amount\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m,\n\u001b[0;32m     12\u001b[0m     impose_crs\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mepsg:26986\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m     13\u001b[0m )\n",
      "Cell \u001b[1;32mIn[4], line 166\u001b[0m, in \u001b[0;36mbetweenness_flow_simulation\u001b[1;34m(city_name, data_folder, output_folder, pairings_file, network_weight_settings, turn_penalty_settings, elastic_weight_settings, num_cores, turn_threshold_degree, turn_penalty_amount, impose_crs)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[39mfor\u001b[39;00m elastic_weight \u001b[39min\u001b[39;00m elastic_weight_settings:\n\u001b[0;32m    163\u001b[0m     \u001b[39m# The order of these is important, as the weight is overriden by\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[39m# elastic weight as there is no clean way to update weight for now.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m elastic_weight:\n\u001b[1;32m--> 166\u001b[0m         get_elastic_weight(\n\u001b[0;32m    167\u001b[0m             zonal\u001b[39m.\u001b[39;49mnetwork,\n\u001b[0;32m    168\u001b[0m             search_radius\u001b[39m=\u001b[39;49m\u001b[39m800\u001b[39;49m,\n\u001b[0;32m    169\u001b[0m             detour_ratio\u001b[39m=\u001b[39;49m\u001b[39m0.002\u001b[39;49m,\n\u001b[0;32m    170\u001b[0m             beta\u001b[39m=\u001b[39;49m\u001b[39m0.002\u001b[39;49m,\n\u001b[0;32m    171\u001b[0m             decay\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    172\u001b[0m             turn_penalty\u001b[39m=\u001b[39;49mturn_penalty,\n\u001b[0;32m    173\u001b[0m             retained_d_idxs\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m  \u001b[39m#<------------------- This is very sensitive to the orfer of iteration. TODO: change to a more solid implementation\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m             \u001b[39m#retained_d_idxs=None\u001b[39;49;00m\n\u001b[0;32m    175\u001b[0m             )\n\u001b[0;32m    177\u001b[0m         logger\u001b[39m.\u001b[39mlog({\n\u001b[0;32m    178\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39morigin\u001b[39m\u001b[39m\"\u001b[39m: pairing[\u001b[39m\"\u001b[39m\u001b[39mOrigin_Name\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    179\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mdestination\u001b[39m\u001b[39m\"\u001b[39m: pairing[\u001b[39m\"\u001b[39m\u001b[39mDestination_Name\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    180\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mevent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mElastic Weights generated.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    181\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mdistance\u001b[39m\u001b[39m\"\u001b[39m: network_weight, \u001b[39m\"\u001b[39m\u001b[39mtune_penalty\u001b[39m\u001b[39m\"\u001b[39m: turn_penalty,\n\u001b[0;32m    182\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39melastic_weight\u001b[39m\u001b[39m\"\u001b[39m: elastic_weight})\n\u001b[0;32m    183\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\56830\\OneDrive - Massachusetts Institute of Technology\\UROPs\\UNA\\madina\\test_ipynb\\..\\madina\\una\\elastic.py:43\u001b[0m, in \u001b[0;36mget_elastic_weight\u001b[1;34m(network, search_radius, detour_ratio, beta, decay, turn_penalty, retained_d_idxs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     access \u001b[39m=\u001b[39m o_reach\n\u001b[1;32m---> 43\u001b[0m min_access \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39;49m(access\u001b[39m.\u001b[39;49mvalues())\n\u001b[0;32m     44\u001b[0m max_access \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(access\u001b[39m.\u001b[39mvalues())\n\u001b[0;32m     45\u001b[0m \u001b[39mfor\u001b[39;00m o_idx \u001b[39min\u001b[39;00m origins\u001b[39m.\u001b[39mindex:\n",
      "\u001b[1;31mValueError\u001b[0m: min() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "betweenness_flow_simulation(\n",
    "    city_name=\"Somerville\",\n",
    "    data_folder=f'Cities\\\\Somerville\\\\Data\\\\',\n",
    "    output_folder=f'Cities\\\\Somerville\\\\Simulations\\\\',\n",
    "    pairings_file=\"Pairings.csv\",\n",
    "    network_weight_settings=[\"Geometric\"],          # [\"Perceived\", \"Geometric\"],\n",
    "    turn_penalty_settings=[True],                   # [False, True]\n",
    "    elastic_weight_settings=[True],          # [False, True]\n",
    "    num_cores=20,\n",
    "    turn_threshold_degree=45,\n",
    "    turn_penalty_amount=30,\n",
    "    impose_crs='epsg:26986'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "    # Running simulations for 5 scenariios\n",
    "for i in reversed(range(6)):\n",
    "    print (f\"----------------------------------Scenario {i}-----------------------\")\n",
    "    betweenness_flow_simulation(\n",
    "        city_name=\"Beirut\",\n",
    "        data_folder=f'Cities\\\\Beirut\\\\scenario_data\\\\SCENARIO{i}\\\\',\n",
    "        output_folder=f'Cities\\\\Beirut\\\\\\scenario_output\\\\SCENARIO{i}\\\\',\n",
    "        pairings_file=\"Pairings.csv\",\n",
    "        network_weight_settings=[\"Perceived\"],          # [\"Perceived\", \"Geometric\"],\n",
    "        turn_penalty_settings=[False],                   # [False, True]\n",
    "        elastic_weight_settings=[True],          # [False, True]\n",
    "        num_cores=48,\n",
    "        turn_threshold_degree=45,\n",
    "        turn_penalty_amount=30,\n",
    "        impose_crs='epsg:32636'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "betweenness_flow_simulation(\n",
    "    city_name=\"Beirut\",\n",
    "    data_folder=f'Cities\\\\Beirut\\\\scenario_data\\\\original\\\\',\n",
    "    output_folder=f'Cities\\\\Beirut\\\\\\scenario_output\\\\original\\\\',\n",
    "    pairings_file=\"Pairings.csv\",\n",
    "    network_weight_settings=[\"Perceived\"],          # [\"Perceived\", \"Geometric\"],\n",
    "    turn_penalty_settings=[False],                   # [False, True]\n",
    "    elastic_weight_settings=[True],          # [False, True]\n",
    "    num_cores=48,\n",
    "    turn_threshold_degree=45,\n",
    "    turn_penalty_amount=30,\n",
    "    impose_crs='epsg:32636'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def accisiility_simulation(\n",
    "        city_name=\"zonal\",\n",
    "        data_folder=None,\n",
    "        output_folder=None,\n",
    "        pairings_file=\"Pairings.csv\",\n",
    "        network_weight_settings = [\"Perceived\", \"Geometric\"],\n",
    "        turn_penalty_settings = [False, True],\n",
    "        elastic_weight_settings = [False, True],\n",
    "        num_cores=8,\n",
    "        turn_threshold_degree=45,\n",
    "        turn_penalty_amount=30,\n",
    "        impose_crs=None\n",
    "    ):\n",
    "    '''\n",
    "    WHat used to be a major project, is now implemented into this standard workflow.....\n",
    "    '''\n",
    "    # TODO: pass turn_penalty_threshold and egree all the way into the function \"turn_penalty_value\". Think of an appropriate way to either assume as a zonal.degree_threshold setting, or literally pass internally into each function?\n",
    "\n",
    "    # Validate user input parameters, raise exceptions or make modifications..\n",
    "    if data_folder is None:\n",
    "        data_folder = \"Cities\\\\\"+city_name+\"\\\\Data\\\\\"\n",
    "    if output_folder is None:\n",
    "        start_time = datetime.now()\n",
    "        output_folder = f\"Cities\\\\{city_name}\\\\Simulations\\\\{start_time.year}-{start_time.month:02d}-{start_time.day:02d} {start_time.hour:02d}-{start_time.minute:02d}\\\\ \"\n",
    "\n",
    "    logger=Logger(output_folder)\n",
    "    logger.log({\"event\": \"beginning\"})\n",
    "\n",
    "    pairings = gpd.read_file(data_folder + pairings_file)\n",
    "\n",
    "    zonal = Zonal()\n",
    "    if impose_crs is not None:\n",
    "        zonal = Zonal(projected_crs=impose_crs)\n",
    "\n",
    "    zonal.load_layer(\n",
    "        layer_name='streets',\n",
    "        file_path=data_folder +  pairings.at[0, \"Network_File\"]  # \"Network.geojson\"\n",
    "    )\n",
    "    if impose_crs is not None:\n",
    "        zonal.layers[\"streets\"][\"gdf\"] = gpd.read_file(data_folder +  pairings.at[0, \"Network_File\"]).set_crs(impose_crs, allow_override=True)\n",
    "\n",
    "    print(f\"streets\\t{zonal.layers['streets'].gdf.crs}\")\n",
    "\n",
    "    logger.simulation_start(zonal, network_weight_settings, turn_penalty_settings, elastic_weight_settings)\n",
    "\n",
    "    ##-------------------------------------------------------------------------------------------------------------< Data Cleaning/...\n",
    "    geometry_gdf = zonal.layers[\"streets\"][\"gdf\"]\n",
    "    polygon_idxs = geometry_gdf[geometry_gdf[\"geometry\"].geom_type == \"Polygon\"].index\n",
    "    geometry_gdf.loc[polygon_idxs,\"geometry\"] = geometry_gdf.loc[polygon_idxs, \"geometry\"].exterior\n",
    "    zonal.layers[\"streets\"][\"gdf\"] = geometry_gdf\n",
    "\n",
    "    if zonal.layers[\"streets\"][\"gdf\"].has_z.any():\n",
    "        def _to_2d(x, y, z):\n",
    "            return tuple(filter(None, [x, y]))\n",
    "        zonal.layers[\"streets\"][\"gdf\"][\"geometry\"] = zonal.layers[\"streets\"][\"gdf\"][\n",
    "            \"geometry\"].apply(lambda s: transform(_to_2d, s))\n",
    "\n",
    "\n",
    "    if (zonal.layers[\"streets\"][\"gdf\"].geometry.geom_type == \"MultiLineString\").all():\n",
    "        zonal.layers[\"streets\"][\"gdf\"][\"geometry\"] = zonal.layers[\"streets\"][\"gdf\"][\n",
    "            \"geometry\"].apply(lambda s: s.geoms[0])\n",
    "\n",
    "    # Setting up a street network\n",
    "    create_street_nodes_edges(\n",
    "        zonal,\n",
    "        source_layer=\"streets\",\n",
    "        flatten_polylines=False,\n",
    "        node_snapping_tolerance=1,\n",
    "        fuse_2_degree_edges=False,\n",
    "        tolerance_angle=10,\n",
    "        solve_intersections=False,\n",
    "        loose_edge_trim_tolerance=0.001,\n",
    "        weight_attribute=None if \"Perceived\" not in network_weight_settings else pairings.at[0, \"Network_Cost\"],\n",
    "        discard_redundant_edges=True # <---------------------------------------TODO: Expose as a parameter\n",
    "        )\n",
    "    # This is to re-set the origins and destinations before any new iteration. TODO: implement as a Zonal function.\n",
    "    clean_node_gdf = zonal.layers[\"network_nodes\"][\"gdf\"].copy(deep=True)\n",
    "\n",
    "    # preparing percieved and geometric weights...\n",
    "    perceived_network_weight = zonal.layers[\"network_edges\"][\"gdf\"][\"weight\"]\n",
    "    perceived_network_weight = perceived_network_weight.apply(lambda x: max(1, x))      # To avoid any negative numbers...\n",
    "    geometric_network_weight = zonal.layers[\"network_edges\"][\"gdf\"][\"geometry\"].length\n",
    "\n",
    "    logger.log({\"event\": \"Network topology created.\"})\n",
    "\n",
    "\n",
    "    for idx, pairing in pairings.iterrows():\n",
    "        # Loading layers,  if they're not already loaded.\n",
    "        if pairing[\"Origin_Name\"] not in zonal.layers:\n",
    "            zonal.load_layer(\n",
    "                layer_name=pairing[\"Origin_Name\"],\n",
    "                file_path=data_folder + pairing[\"Origin_File\"]\n",
    "            )\n",
    "            if (impose_crs is not None) and (zonal.layers[pairing[\"Origin_Name\"]]['original_crs'] != impose_crs):\n",
    "                zonal.layers[pairing[\"Origin_Name\"]][\"gdf\"] = gpd.read_file(data_folder + pairing[\"Origin_File\"]).set_crs(impose_crs, allow_override=True)\n",
    "                zonal.layers[pairing[\"Origin_Name\"]]['original_crs'] = impose_crs\n",
    "\n",
    "            ##-------------------------------------------------------------------------------------------------------------< Data Cleaning/...\n",
    "            if zonal.layers[pairing[\"Origin_Name\"]][\"gdf\"].has_z.any():\n",
    "                zonal.layers[pairing[\"Origin_Name\"]][\"gdf\"][\"geometry\"] = zonal.layers[pairing[\"Origin_Name\"]][\"gdf\"][\"geometry\"].apply(\n",
    "                    lambda s: transform(_to_2d, s))\n",
    "        if pairing[\"Destination_Name\"] not in zonal.layers:\n",
    "            zonal.load_layer(\n",
    "                layer_name=pairing[\"Destination_Name\"],\n",
    "                file_path=data_folder + pairing[\"Destination_File\"]\n",
    "            )\n",
    "            if (impose_crs is not None) and (zonal.layers[pairing[\"Destination_Name\"]]['original_crs'] != impose_crs):\n",
    "                zonal.layers[pairing[\"Destination_Name\"]][\"gdf\"] = gpd.read_file(data_folder + pairing[\"Destination_File\"]).set_crs(impose_crs, allow_override=True)\n",
    "                zonal.layers[pairing[\"Destination_Name\"]]['original_crs'] = impose_crs\n",
    "            ##-------------------------------------------------------------------------------------------------------------< Data Cleaning/...\n",
    "            if zonal.layers[pairing[\"Destination_Name\"]][\"gdf\"].has_z.any():\n",
    "                zonal.layers[pairing[\"Destination_Name\"]][\"gdf\"][\"geometry\"] = zonal.layers[pairing[\"Destination_Name\"]][\"gdf\"][\n",
    "                    \"geometry\"].apply(lambda s: transform(_to_2d, s))\n",
    "        print(f\"{pairing['Origin_Name']}\\t{zonal.layers[pairing['Origin_Name']]['gdf'].crs}\")\n",
    "        print(f\"{pairing['Destination_Name']}\\t{zonal.layers[pairing['Destination_Name']]['gdf'].crs}\")\n",
    "\n",
    "        # making sure to clear any existing origins and destinations before adding new ones.\n",
    "        zonal.layers[\"network_nodes\"][\"gdf\"] = clean_node_gdf.copy(deep=True)\n",
    "\n",
    "        # iterating over network weight options..\n",
    "        for network_weight in network_weight_settings:\n",
    "\n",
    "            # setting the proper network_weight\n",
    "            if network_weight == \"Perceived\":\n",
    "                zonal.layers[\"network_edges\"][\"gdf\"][\"weight\"] = perceived_network_weight\n",
    "            elif network_weight == \"Geometric\":\n",
    "                zonal.layers[\"network_edges\"][\"gdf\"][\"weight\"] = geometric_network_weight\n",
    "\n",
    "            # using an effecient insert algorithm TODO: should be built inti the main Madina code... currently imported from betweenness function..\n",
    "            insert_nodes_v2(\n",
    "                zonal,\n",
    "                label=\"origin\",\n",
    "                layer_name=pairing[\"Origin_Name\"],\n",
    "                weight_attribute=pairing[\"Origin_Weight\"] if pairing[\"Origin_Weight\"] != \"Count\" else None,\n",
    "            )\n",
    "\n",
    "            insert_nodes_v2(\n",
    "                zonal,\n",
    "                label=\"destination\",\n",
    "                layer_name=pairing[\"Destination_Name\"],\n",
    "                weight_attribute=pairing[\"Destination_Weight\"] if pairing[\"Destination_Weight\"] != \"Count\" else None,\n",
    "            )\n",
    "\n",
    "            inelastic_weight = zonal.layers[\"network_nodes\"][\"gdf\"]['weight']\n",
    "\n",
    "\n",
    "            logger.log({\n",
    "                \"origin\": pairing[\"Origin_Name\"],\n",
    "                \"destination\": pairing[\"Destination_Name\"],\n",
    "                \"event\": \"Origins and Destinations prepared.\"\n",
    "                })\n",
    "\n",
    "            zonal.create_graph(light_graph=True, dense_graph=True)\n",
    "\n",
    "            logger.log({\n",
    "                \"origin\": pairing[\"Origin_Name\"],\n",
    "                \"destination\": pairing[\"Destination_Name\"],\n",
    "                \"event\": \"Light and dense graphs prepared.\"\n",
    "                })\n",
    "\n",
    "            for turn_penalty in turn_penalty_settings:\n",
    "                # TODO: Investigate the value of pasing internal calculations beween simulations..\n",
    "                #retained_d_idxs = {}\n",
    "                #retained_paths = {}\n",
    "                #retained_distances = {}\n",
    "                for elastic_weight in elastic_weight_settings:\n",
    "                    # The order of these is important, as the weight is overriden by\n",
    "                    # elastic weight as there is no clean way to update weight for now.\n",
    "                    if elastic_weight:\n",
    "                        get_elastic_weight(\n",
    "                            zonal,\n",
    "                            search_radius=800,\n",
    "                            detour_ratio=0.002,\n",
    "                            beta=0.002,\n",
    "                            decay=True,\n",
    "                            turn_penalty=turn_penalty,\n",
    "                            retained_d_idxs=None  #<------------------- This is very sensitive to the orfer of iteration. TODO: change to a more solid implementation\n",
    "                            #retained_d_idxs=None\n",
    "                            )\n",
    "\n",
    "                        logger.log({\n",
    "                            \"origin\": pairing[\"Origin_Name\"],\n",
    "                            \"destination\": pairing[\"Destination_Name\"],\n",
    "                            \"event\": \"Elastic Weights generated.\",\n",
    "                            \"distance\": network_weight, \"tune_penalty\": turn_penalty,\n",
    "                            \"elastic_weight\": elastic_weight})\n",
    "                    else:\n",
    "                        zonal.layers[\"network_nodes\"][\"gdf\"]['weight'] = inelastic_weight\n",
    "\n",
    "\n",
    "                    node_gdf = zonal.layers[\"network_nodes\"][\"gdf\"]\n",
    "                    origin_gdf = node_gdf[node_gdf[\"type\"] == \"origin\"]\n",
    "                    origin_gdf.rename(\n",
    "                        columns={\n",
    "                            \"elastic_weight\": f\"elastic_weight_O({pairing['Origin_Name']})__D({pairing['Origin_Name']})_{network_weight}_{'with_turns' if turn_penalty else 'no_turns'}_{'elastic_weight' if elastic_weight else 'unadjusted_weight'})\",\n",
    "                            \"gravity\": f\"gravity_O({pairing['Origin_Name']})__D({pairing['Origin_Name']})_{network_weight}_{'with_turns' if turn_penalty else 'no_turns'}_{'elastic_weight' if elastic_weight else 'unadjusted_weight'})\",\n",
    "                            \"reach\": f\"reach_O({pairing['Origin_Name']})__D({pairing['Origin_Name']})_{network_weight}_{'with_turns' if turn_penalty else 'no_turns'}_{'elastic_weight' if elastic_weight else 'unadjusted_weight'})\"\n",
    "                        }\n",
    "                    )\n",
    "                    pairing_folder = output_folder + f\"{network_weight}\\\\{'with_turns' if turn_penalty else 'no_turns'}\\\\{'elastic_weight' if elastic_weight else 'unadjusted_weight'}\\\\O({pairing['Origin_Name']})_D({pairing['Destination_Name']})\\\\\"\n",
    "                    origin_gdf.to_csv(pairing_folder + \"reach_gravity_elastic_weight.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in reversed(range(7)):\n",
    "    print (f\"----------------------------------Scenario {i}-----------------------\")\n",
    "    accisiility_simulation(\n",
    "        city_name=\"Beirut\",\n",
    "        data_folder=f'Cities\\\\Beirut\\\\scenario_data\\\\SCENARIO{i}\\\\',\n",
    "        output_folder=f'Cities\\\\Beirut\\\\\\scenario_output\\\\SCENARIO{i}\\\\',\n",
    "        pairings_file=\"Pairings.csv\",\n",
    "        network_weight_settings=[\"Perceived\"],          # [\"Perceived\", \"Geometric\"],\n",
    "        turn_penalty_settings=[False],                   # [False, True]\n",
    "        elastic_weight_settings=[True],          # [False, True]\n",
    "        num_cores=48,\n",
    "        turn_threshold_degree=45,\n",
    "        turn_penalty_amount=30,\n",
    "        impose_crs='epsg:32636'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Running simulations for 5 scenariios\n",
    "for i in range(7):\n",
    "    print (f\"----------------------------------Scenario {i}-----------------------\")\n",
    "    betweenness_flow_simulation(\n",
    "        city_name=\"Beirut\",\n",
    "        data_folder='Cities\\\\Beirut\\\\scenario_data\\\\SCENARIO'+str(i)+\"\\\\\",\n",
    "        output_folder='Cities\\\\Beirut\\\\\\scenario_output\\\\SCENARIO'+str(i)+\"\\\\\",    \n",
    "        #pairings_file=\"Pairings.csv\",\n",
    "        network_weight_settings=[\"Perceived\"],          # [\"Perceived\", \"Geometric\"],\n",
    "        turn_penalty_settings=[False],                   # [False, True]\n",
    "        elastic_weight_settings=[True],          # [False, True]\n",
    "        num_cores=48,\n",
    "        turn_threshold_degree=45,\n",
    "        turn_penalty_amount=30\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
